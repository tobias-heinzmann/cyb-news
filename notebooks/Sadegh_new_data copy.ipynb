{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca0d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from cybnews.data import get_data, preprocessing, welf_preprocessing, join_text, cc_preprocessing, fnc_preprocessing\n",
    "from cybnews.model import train_test_split_data, create_new_model, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec9f050",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m chunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/ssadegh/Downloads/FakeNewsCorpus-master/news_cleaned_2018_02_13.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39mchunksize) \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(reader):\n\u001b[1;32m      7\u001b[0m         chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m         chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "#news_cleaned_2018_02_13.csv\n",
    "\n",
    "# chunksize = 10000\n",
    "\n",
    "# with pd.read_csv('/Users/ssadegh/Downloads/FakeNewsCorpus-master/news_cleaned_2018_02_13.csv', chunksize=chunksize) as reader:\n",
    "#     for i, chunk in enumerate(reader):\n",
    "#         chunk[\"text\"] = chunk[\"content\"]\n",
    "#         chunk[\"label\"] = chunk[\"type\"]\n",
    "#         relevant_columns = ['text', 'label', 'title']\n",
    "#         chunk = chunk[relevant_columns]\n",
    "#         chunk = chunk[chunk['label'].isin(['reliable', 'fake'])]\n",
    "\n",
    "#         label_mapping = {'fake': 1, 'reliable': 0}\n",
    "#         chunk['label'] = chunk['label'].map(label_mapping)\n",
    "\n",
    "#         mode = 'w' if i == 0 else 'a'\n",
    "#         header = (i == 0)\n",
    "#         chunk.to_csv('/Users/ssadegh/Downloads/FakeNewsCorpus-master/processed_news.csv', mode=mode, header=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc48606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to pre-process the CSV to filter out bad lines...\n",
      "Processed 0 lines...\n",
      "Processed 100000 lines...\n",
      "Processed 200000 lines...\n",
      "Processed 300000 lines...\n",
      "Processed 400000 lines...\n",
      "Processed 500000 lines...\n",
      "Processed 600000 lines...\n",
      "Processed 700000 lines...\n",
      "Processed 800000 lines...\n",
      "Processed 900000 lines...\n",
      "Processed 1000000 lines...\n",
      "Processed 1100000 lines...\n",
      "Processed 1200000 lines...\n",
      "Processed 1300000 lines...\n",
      "Processed 1400000 lines...\n",
      "Processed 1500000 lines...\n",
      "Processed 1600000 lines...\n",
      "Processed 1700000 lines...\n",
      "Processed 1800000 lines...\n",
      "Processed 1900000 lines...\n",
      "Processed 2000000 lines...\n",
      "Processed 2100000 lines...\n",
      "Processed 2200000 lines...\n",
      "Processed 2300000 lines...\n",
      "Processed 2400000 lines...\n",
      "Processed 2500000 lines...\n",
      "Processed 2600000 lines...\n",
      "Processed 2700000 lines...\n",
      "Processed 2800000 lines...\n",
      "Processed 2900000 lines...\n",
      "Processed 3000000 lines...\n",
      "Processed 3100000 lines...\n",
      "Processed 3200000 lines...\n",
      "Processed 3300000 lines...\n",
      "Processed 3400000 lines...\n",
      "Processed 3500000 lines...\n",
      "Processed 3600000 lines...\n",
      "Processed 3700000 lines...\n",
      "Processed 3800000 lines...\n",
      "Processed 3900000 lines...\n",
      "Processed 4000000 lines...\n",
      "Processed 4100000 lines...\n",
      "Processed 4200000 lines...\n",
      "Processed 4300000 lines...\n",
      "Processed 4400000 lines...\n",
      "Processed 4500000 lines...\n",
      "Processed 4600000 lines...\n",
      "Processed 4700000 lines...\n",
      "Processed 4800000 lines...\n",
      "Processed 4900000 lines...\n",
      "Processed 5000000 lines...\n",
      "Processed 5100000 lines...\n",
      "Processed 5200000 lines...\n",
      "Processed 5300000 lines...\n",
      "Processed 5400000 lines...\n",
      "Processed 5500000 lines...\n",
      "Processed 5600000 lines...\n",
      "Processed 5700000 lines...\n",
      "Processed 5800000 lines...\n",
      "Processed 5900000 lines...\n",
      "Processed 6000000 lines...\n",
      "Processed 6100000 lines...\n",
      "Processed 6200000 lines...\n",
      "Processed 6300000 lines...\n",
      "Processed 6400000 lines...\n",
      "Processed 6500000 lines...\n",
      "Processed 6600000 lines...\n",
      "Processed 6700000 lines...\n",
      "Processed 6800000 lines...\n",
      "Processed 6900000 lines...\n",
      "Processed 7000000 lines...\n",
      "Processed 7100000 lines...\n",
      "Processed 7200000 lines...\n",
      "Processed 7300000 lines...\n",
      "Processed 7400000 lines...\n",
      "Processed 7500000 lines...\n",
      "Processed 7600000 lines...\n",
      "Processed 7700000 lines...\n",
      "Processed 7800000 lines...\n",
      "Processed 7900000 lines...\n",
      "Processed 8000000 lines...\n",
      "Processed 8100000 lines...\n",
      "Processed 8200000 lines...\n",
      "Processed 8300000 lines...\n",
      "Processed 8400000 lines...\n",
      "Processed 8500000 lines...\n",
      "Processed 8600000 lines...\n",
      "Processed 8700000 lines...\n",
      "Processed 8800000 lines...\n",
      "Processed 8900000 lines...\n",
      "Processed 9000000 lines...\n",
      "Processed 9100000 lines...\n",
      "Processed 9200000 lines...\n",
      "Processed 9300000 lines...\n",
      "Processed 9400000 lines...\n",
      "Processed 9500000 lines...\n",
      "Processed 9600000 lines...\n",
      "Processed 9700000 lines...\n",
      "Processed 9800000 lines...\n",
      "Processed 9900000 lines...\n",
      "Processed 10000000 lines...\n",
      "Processed 10100000 lines...\n",
      "Processed 10200000 lines...\n",
      "Processed 10300000 lines...\n",
      "Processed 10400000 lines...\n",
      "Processed 10500000 lines...\n",
      "Processed 10600000 lines...\n",
      "Processed 10700000 lines...\n",
      "Processed 10800000 lines...\n",
      "Processed 10900000 lines...\n",
      "Processed 11000000 lines...\n",
      "Processed 11100000 lines...\n",
      "Processed 11200000 lines...\n",
      "Processed 11300000 lines...\n",
      "Processed 11400000 lines...\n",
      "Processed 11500000 lines...\n",
      "Processed 11600000 lines...\n",
      "Processed 11700000 lines...\n",
      "Processed 11800000 lines...\n",
      "Processed 11900000 lines...\n",
      "Processed 12000000 lines...\n",
      "Processed 12100000 lines...\n",
      "Processed 12200000 lines...\n",
      "Processed 12300000 lines...\n",
      "Processed 12400000 lines...\n",
      "Processed 12500000 lines...\n",
      "Processed 12600000 lines...\n",
      "Processed 12700000 lines...\n",
      "Processed 12800000 lines...\n",
      "Processed 12900000 lines...\n",
      "Processed 13000000 lines...\n",
      "Processed 13100000 lines...\n",
      "Processed 13200000 lines...\n",
      "Processed 13300000 lines...\n",
      "Processed 13400000 lines...\n",
      "Processed 13500000 lines...\n",
      "Processed 13600000 lines...\n",
      "Processed 13700000 lines...\n",
      "Processed 13800000 lines...\n",
      "Processed 13900000 lines...\n",
      "Processed 14000000 lines...\n",
      "Processed 14100000 lines...\n",
      "Processed 14200000 lines...\n",
      "Processed 14300000 lines...\n",
      "Processed 14400000 lines...\n",
      "Processed 14500000 lines...\n",
      "Processed 14600000 lines...\n",
      "Processed 14700000 lines...\n",
      "Processed 14800000 lines...\n",
      "Processed 14900000 lines...\n",
      "Processed 15000000 lines...\n",
      "Processed 15100000 lines...\n",
      "Processed 15200000 lines...\n",
      "Processed 15300000 lines...\n",
      "Processed 15400000 lines...\n",
      "Processed 15500000 lines...\n",
      "Processed 15600000 lines...\n",
      "Processed 15700000 lines...\n",
      "Processed 15800000 lines...\n",
      "Processed 15900000 lines...\n",
      "Processed 16000000 lines...\n",
      "Processed 16100000 lines...\n",
      "Processed 16200000 lines...\n",
      "Processed 16300000 lines...\n",
      "Processed 16400000 lines...\n",
      "Processed 16500000 lines...\n",
      "Processed 16600000 lines...\n",
      "Processed 16700000 lines...\n",
      "Processed 16800000 lines...\n",
      "Processed 16900000 lines...\n",
      "Processed 17000000 lines...\n",
      "Processed 17100000 lines...\n",
      "Processed 17200000 lines...\n",
      "Processed 17300000 lines...\n",
      "Processed 17400000 lines...\n",
      "Processed 17500000 lines...\n",
      "Processed 17600000 lines...\n",
      "Processed 17700000 lines...\n",
      "Processed 17800000 lines...\n",
      "Processed 17900000 lines...\n",
      "Processed 18000000 lines...\n",
      "Processed 18100000 lines...\n",
      "Processed 18200000 lines...\n",
      "Processed 18300000 lines...\n",
      "Processed 18400000 lines...\n",
      "Processed 18500000 lines...\n",
      "Processed 18600000 lines...\n",
      "Processed 18700000 lines...\n",
      "Processed 18800000 lines...\n",
      "Processed 18900000 lines...\n",
      "Processed 19000000 lines...\n",
      "Processed 19100000 lines...\n",
      "Processed 19200000 lines...\n",
      "Processed 19300000 lines...\n",
      "Processed 19400000 lines...\n",
      "Processed 19500000 lines...\n",
      "Processed 19600000 lines...\n",
      "Processed 19700000 lines...\n",
      "Processed 19800000 lines...\n",
      "Processed 19900000 lines...\n",
      "Processed 20000000 lines...\n",
      "Processed 20100000 lines...\n",
      "Processed 20200000 lines...\n",
      "Processed 20300000 lines...\n",
      "Processed 20400000 lines...\n",
      "Processed 20500000 lines...\n",
      "Processed 20600000 lines...\n",
      "Processed 20700000 lines...\n",
      "Processed 20800000 lines...\n",
      "Processed 20900000 lines...\n",
      "Processed 21000000 lines...\n",
      "Processed 21100000 lines...\n",
      "Processed 21200000 lines...\n",
      "Processed 21300000 lines...\n",
      "Processed 21400000 lines...\n",
      "Processed 21500000 lines...\n",
      "Processed 21600000 lines...\n",
      "Processed 21700000 lines...\n",
      "Processed 21800000 lines...\n",
      "Processed 21900000 lines...\n",
      "Processed 22000000 lines...\n",
      "Processed 22100000 lines...\n",
      "Processed 22200000 lines...\n",
      "Processed 22300000 lines...\n",
      "Processed 22400000 lines...\n",
      "Processed 22500000 lines...\n",
      "Processed 22600000 lines...\n",
      "Processed 22700000 lines...\n",
      "Processed 22800000 lines...\n",
      "Processed 22900000 lines...\n",
      "Processed 23000000 lines...\n",
      "Processed 23100000 lines...\n",
      "Processed 23200000 lines...\n",
      "Processed 23300000 lines...\n",
      "Processed 23400000 lines...\n",
      "Processed 23500000 lines...\n",
      "Processed 23600000 lines...\n",
      "Processed 23700000 lines...\n",
      "Processed 23800000 lines...\n",
      "Processed 23900000 lines...\n",
      "Processed 24000000 lines...\n",
      "Processed 24100000 lines...\n",
      "Processed 24200000 lines...\n",
      "Processed 24300000 lines...\n",
      "Processed 24400000 lines...\n",
      "Processed 24500000 lines...\n",
      "Processed 24600000 lines...\n",
      "Processed 24700000 lines...\n",
      "Processed 24800000 lines...\n",
      "Processed 24900000 lines...\n",
      "Processed 25000000 lines...\n",
      "Processed 25100000 lines...\n",
      "Processed 25200000 lines...\n",
      "Processed 25300000 lines...\n",
      "Processed 25400000 lines...\n",
      "Processed 25500000 lines...\n",
      "Processed 25600000 lines...\n",
      "Processed 25700000 lines...\n",
      "Processed 25800000 lines...\n",
      "Processed 25900000 lines...\n",
      "Processed 26000000 lines...\n",
      "Processed 26100000 lines...\n",
      "Processed 26200000 lines...\n",
      "Processed 26300000 lines...\n",
      "Processed 26400000 lines...\n",
      "Processed 26500000 lines...\n",
      "Processed 26600000 lines...\n",
      "Processed 26700000 lines...\n",
      "Processed 26800000 lines...\n",
      "Processed 26900000 lines...\n",
      "Processed 27000000 lines...\n",
      "Processed 27100000 lines...\n",
      "Processed 27200000 lines...\n",
      "Processed 27300000 lines...\n",
      "Processed 27400000 lines...\n",
      "Processed 27500000 lines...\n",
      "Processed 27600000 lines...\n",
      "Processed 27700000 lines...\n",
      "Processed 27800000 lines...\n",
      "Processed 27900000 lines...\n",
      "Processed 28000000 lines...\n",
      "Processed 28100000 lines...\n",
      "Processed 28200000 lines...\n",
      "Processed 28300000 lines...\n",
      "Processed 28400000 lines...\n",
      "Processed 28500000 lines...\n",
      "Processed 28600000 lines...\n",
      "Processed 28700000 lines...\n",
      "Processed 28800000 lines...\n",
      "Processed 28900000 lines...\n",
      "Processed 29000000 lines...\n",
      "Processed 29100000 lines...\n",
      "Processed 29200000 lines...\n",
      "Processed 29300000 lines...\n",
      "Processed 29400000 lines...\n",
      "Processed 29500000 lines...\n",
      "Processed 29600000 lines...\n",
      "Processed 29700000 lines...\n",
      "Processed 29800000 lines...\n",
      "Processed 29900000 lines...\n",
      "Processed 30000000 lines...\n",
      "Processed 30100000 lines...\n",
      "Processed 30200000 lines...\n",
      "Processed 30300000 lines...\n",
      "Processed 30400000 lines...\n",
      "Processed 30500000 lines...\n",
      "Processed 30600000 lines...\n",
      "Processed 30700000 lines...\n",
      "Processed 30800000 lines...\n",
      "Processed 30900000 lines...\n",
      "Processed 31000000 lines...\n",
      "Processed 31100000 lines...\n",
      "Processed 31200000 lines...\n",
      "Processed 31300000 lines...\n",
      "Processed 31400000 lines...\n",
      "Processed 31500000 lines...\n",
      "Processed 31600000 lines...\n",
      "Processed 31700000 lines...\n",
      "Processed 31800000 lines...\n",
      "Processed 31900000 lines...\n",
      "Processed 32000000 lines...\n",
      "Processed 32100000 lines...\n",
      "Processed 32200000 lines...\n",
      "Processed 32300000 lines...\n",
      "Processed 32400000 lines...\n",
      "Processed 32500000 lines...\n",
      "Processed 32600000 lines...\n",
      "Processed 32700000 lines...\n",
      "Processed 32800000 lines...\n",
      "Processed 32900000 lines...\n",
      "Processed 33000000 lines...\n",
      "Processed 33100000 lines...\n",
      "Processed 33200000 lines...\n",
      "Processed 33300000 lines...\n",
      "Processed 33400000 lines...\n",
      "Processed 33500000 lines...\n",
      "Processed 33600000 lines...\n",
      "Processed 33700000 lines...\n",
      "Processed 33800000 lines...\n",
      "Processed 33900000 lines...\n",
      "Processed 34000000 lines...\n",
      "Processed 34100000 lines...\n",
      "Processed 34200000 lines...\n",
      "Processed 34300000 lines...\n",
      "Processed 34400000 lines...\n",
      "Processed 34500000 lines...\n",
      "Processed 34600000 lines...\n",
      "Processed 34700000 lines...\n",
      "Processed 34800000 lines...\n",
      "Processed 34900000 lines...\n",
      "Processed 35000000 lines...\n",
      "Processed 35100000 lines...\n",
      "Processed 35200000 lines...\n",
      "Processed 35300000 lines...\n",
      "Processed 35400000 lines...\n",
      "Processed 35500000 lines...\n",
      "Processed 35600000 lines...\n",
      "Processed 35700000 lines...\n",
      "Processed 35800000 lines...\n",
      "Processed 35900000 lines...\n",
      "Processed 36000000 lines...\n",
      "Processed 36100000 lines...\n",
      "Processed 36200000 lines...\n",
      "Processed 36300000 lines...\n",
      "Processed 36400000 lines...\n",
      "Processed 36500000 lines...\n",
      "Processed 36600000 lines...\n",
      "Processed 36700000 lines...\n",
      "Processed 36800000 lines...\n",
      "Processed 36900000 lines...\n",
      "Processed 37000000 lines...\n",
      "Processed 37100000 lines...\n",
      "Processed 37200000 lines...\n",
      "Processed 37300000 lines...\n",
      "Processed 37400000 lines...\n",
      "Processed 37500000 lines...\n",
      "Processed 37600000 lines...\n",
      "Processed 37700000 lines...\n",
      "Processed 37800000 lines...\n",
      "Processed 37900000 lines...\n",
      "Processed 38000000 lines...\n",
      "Processed 38100000 lines...\n",
      "Processed 38200000 lines...\n",
      "Processed 38300000 lines...\n",
      "Processed 38400000 lines...\n",
      "Processed 38500000 lines...\n",
      "Processed 38600000 lines...\n",
      "Processed 38700000 lines...\n",
      "Processed 38800000 lines...\n",
      "Processed 38900000 lines...\n",
      "Processed 39000000 lines...\n",
      "Processed 39100000 lines...\n",
      "Processed 39200000 lines...\n",
      "Processed 39300000 lines...\n",
      "Processed 39400000 lines...\n",
      "Processed 39500000 lines...\n",
      "Processed 39600000 lines...\n",
      "Processed 39700000 lines...\n",
      "Processed 39800000 lines...\n",
      "Processed 39900000 lines...\n",
      "Processed 40000000 lines...\n",
      "Processed 40100000 lines...\n",
      "Processed 40200000 lines...\n",
      "Processed 40300000 lines...\n",
      "Processed 40400000 lines...\n",
      "Processed 40500000 lines...\n",
      "Processed 40600000 lines...\n",
      "Processed 40700000 lines...\n",
      "Processed 40800000 lines...\n",
      "Processed 40900000 lines...\n",
      "Processed 41000000 lines...\n",
      "Processed 41100000 lines...\n",
      "Processed 41200000 lines...\n",
      "Processed 41300000 lines...\n",
      "Processed 41400000 lines...\n",
      "Processed 41500000 lines...\n",
      "Processed 41600000 lines...\n",
      "Processed 41700000 lines...\n",
      "Processed 41800000 lines...\n",
      "Processed 41900000 lines...\n",
      "Processed 42000000 lines...\n",
      "Processed 42100000 lines...\n",
      "Processed 42200000 lines...\n",
      "Processed 42300000 lines...\n",
      "Processed 42400000 lines...\n",
      "Processed 42500000 lines...\n",
      "Processed 42600000 lines...\n",
      "Processed 42700000 lines...\n",
      "Processed 42800000 lines...\n",
      "Processed 42900000 lines...\n",
      "Processed 43000000 lines...\n",
      "Processed 43100000 lines...\n",
      "Processed 43200000 lines...\n",
      "Processed 43300000 lines...\n",
      "Processed 43400000 lines...\n",
      "Processed 43500000 lines...\n",
      "Processed 43600000 lines...\n",
      "Processed 43700000 lines...\n",
      "Processed 43800000 lines...\n",
      "Processed 43900000 lines...\n",
      "Processed 44000000 lines...\n",
      "Processed 44100000 lines...\n",
      "Processed 44200000 lines...\n",
      "Processed 44300000 lines...\n",
      "Processed 44400000 lines...\n",
      "Processed 44500000 lines...\n",
      "Processed 44600000 lines...\n",
      "Processed 44700000 lines...\n",
      "Processed 44800000 lines...\n",
      "Processed 44900000 lines...\n",
      "Processed 45000000 lines...\n",
      "Processed 45100000 lines...\n",
      "Processed 45200000 lines...\n",
      "Processed 45300000 lines...\n",
      "Processed 45400000 lines...\n",
      "Processed 45500000 lines...\n",
      "Processed 45600000 lines...\n",
      "Processed 45700000 lines...\n",
      "Processed 45800000 lines...\n",
      "Processed 45900000 lines...\n",
      "Processed 46000000 lines...\n",
      "Processed 46100000 lines...\n",
      "Processed 46200000 lines...\n",
      "Processed 46300000 lines...\n",
      "Processed 46400000 lines...\n",
      "Processed 46500000 lines...\n",
      "Processed 46600000 lines...\n",
      "Processed 46700000 lines...\n",
      "Processed 46800000 lines...\n",
      "Processed 46900000 lines...\n",
      "Processed 47000000 lines...\n",
      "Processed 47100000 lines...\n",
      "Processed 47200000 lines...\n",
      "Processed 47300000 lines...\n",
      "Processed 47400000 lines...\n",
      "Processed 47500000 lines...\n",
      "Processed 47600000 lines...\n",
      "Processed 47700000 lines...\n",
      "Processed 47800000 lines...\n",
      "Processed 47900000 lines...\n",
      "Processed 48000000 lines...\n",
      "Processed 48100000 lines...\n",
      "Processed 48200000 lines...\n",
      "Processed 48300000 lines...\n",
      "Processed 48400000 lines...\n",
      "Processed 48500000 lines...\n",
      "Processed 48600000 lines...\n",
      "Processed 48700000 lines...\n",
      "Processed 48800000 lines...\n",
      "Processed 48900000 lines...\n",
      "Processed 49000000 lines...\n",
      "Processed 49100000 lines...\n",
      "Processed 49200000 lines...\n",
      "Processed 49300000 lines...\n",
      "Processed 49400000 lines...\n",
      "Processed 49500000 lines...\n",
      "Processed 49600000 lines...\n",
      "Processed 49700000 lines...\n",
      "Processed 49800000 lines...\n",
      "Processed 49900000 lines...\n",
      "Processed 50000000 lines...\n",
      "Processed 50100000 lines...\n",
      "Processed 50200000 lines...\n",
      "Processed 50300000 lines...\n",
      "Processed 50400000 lines...\n",
      "Processed 50500000 lines...\n",
      "Processed 50600000 lines...\n",
      "Processed 50700000 lines...\n",
      "Processed 50800000 lines...\n",
      "Processed 50900000 lines...\n",
      "Processed 51000000 lines...\n",
      "Processed 51100000 lines...\n",
      "Processed 51200000 lines...\n",
      "Processed 51300000 lines...\n",
      "Processed 51400000 lines...\n",
      "Processed 51500000 lines...\n",
      "Processed 51600000 lines...\n",
      "Processed 51700000 lines...\n",
      "Processed 51800000 lines...\n",
      "Processed 51900000 lines...\n",
      "Processed 52000000 lines...\n",
      "Processed 52100000 lines...\n",
      "Processed 52200000 lines...\n",
      "Processed 52300000 lines...\n",
      "Processed 52400000 lines...\n",
      "Processed 52500000 lines...\n",
      "Processed 52600000 lines...\n",
      "Processed 52700000 lines...\n",
      "Processed 52800000 lines...\n",
      "Processed 52900000 lines...\n",
      "Processed 53000000 lines...\n",
      "Processed 53100000 lines...\n",
      "Processed 53200000 lines...\n",
      "Processed 53300000 lines...\n",
      "Processed 53400000 lines...\n",
      "Processed 53500000 lines...\n",
      "Processed 53600000 lines...\n",
      "Processed 53700000 lines...\n",
      "Processed 53800000 lines...\n",
      "Processed 53900000 lines...\n",
      "Processed 54000000 lines...\n",
      "Processed 54100000 lines...\n",
      "Processed 54200000 lines...\n",
      "Processed 54300000 lines...\n",
      "Processed 54400000 lines...\n",
      "Processed 54500000 lines...\n",
      "Processed 54600000 lines...\n",
      "Processed 54700000 lines...\n",
      "Processed 54800000 lines...\n",
      "Processed 54900000 lines...\n",
      "Processed 55000000 lines...\n",
      "Processed 55100000 lines...\n",
      "Processed 55200000 lines...\n",
      "Processed 55300000 lines...\n",
      "Processed 55400000 lines...\n",
      "Processed 55500000 lines...\n",
      "Processed 55600000 lines...\n",
      "Processed 55700000 lines...\n",
      "Processed 55800000 lines...\n",
      "Processed 55900000 lines...\n",
      "Processed 56000000 lines...\n",
      "Processed 56100000 lines...\n",
      "Processed 56200000 lines...\n",
      "Processed 56300000 lines...\n",
      "Processed 56400000 lines...\n",
      "Processed 56500000 lines...\n",
      "Processed 56600000 lines...\n",
      "Processed 56700000 lines...\n",
      "Processed 56800000 lines...\n",
      "Processed 56900000 lines...\n",
      "Processed 57000000 lines...\n",
      "Processed 57100000 lines...\n",
      "Processed 57200000 lines...\n",
      "Processed 57300000 lines...\n",
      "Processed 57400000 lines...\n",
      "Processed 57500000 lines...\n",
      "Processed 57600000 lines...\n",
      "Processed 57700000 lines...\n",
      "Processed 57800000 lines...\n",
      "Processed 57900000 lines...\n",
      "Processed 58000000 lines...\n",
      "Processed 58100000 lines...\n",
      "Processed 58200000 lines...\n",
      "Processed 58300000 lines...\n",
      "Processed 58400000 lines...\n",
      "Processed 58500000 lines...\n",
      "Processed 58600000 lines...\n",
      "Processed 58700000 lines...\n",
      "Processed 58800000 lines...\n",
      "Processed 58900000 lines...\n",
      "Processed 59000000 lines...\n",
      "Processed 59100000 lines...\n",
      "Processed 59200000 lines...\n",
      "Processed 59300000 lines...\n",
      "Processed 59400000 lines...\n",
      "Processed 59500000 lines...\n",
      "Processed 59600000 lines...\n",
      "Processed 59700000 lines...\n",
      "Processed 59800000 lines...\n",
      "Processed 59900000 lines...\n",
      "Processed 60000000 lines...\n",
      "Processed 60100000 lines...\n",
      "Processed 60200000 lines...\n",
      "Processed 60300000 lines...\n",
      "Processed 60400000 lines...\n",
      "Processed 60500000 lines...\n",
      "Processed 60600000 lines...\n",
      "Processed 60700000 lines...\n",
      "Processed 60800000 lines...\n",
      "Processed 60900000 lines...\n",
      "Processed 61000000 lines...\n",
      "Processed 61100000 lines...\n",
      "Processed 61200000 lines...\n",
      "Processed 61300000 lines...\n",
      "Processed 61400000 lines...\n",
      "Processed 61500000 lines...\n",
      "Processed 61600000 lines...\n",
      "Processed 61700000 lines...\n",
      "Processed 61800000 lines...\n",
      "Processed 61900000 lines...\n",
      "Processed 62000000 lines...\n",
      "Processed 62100000 lines...\n",
      "Processed 62200000 lines...\n",
      "Processed 62300000 lines...\n",
      "Processed 62400000 lines...\n",
      "Processed 62500000 lines...\n",
      "Processed 62600000 lines...\n",
      "Processed 62700000 lines...\n",
      "Processed 62800000 lines...\n",
      "Processed 62900000 lines...\n",
      "Processed 63000000 lines...\n",
      "Processed 63100000 lines...\n",
      "Processed 63200000 lines...\n",
      "Processed 63300000 lines...\n",
      "Processed 63400000 lines...\n",
      "Processed 63500000 lines...\n",
      "Processed 63600000 lines...\n",
      "Processed 63700000 lines...\n",
      "Processed 63800000 lines...\n",
      "Processed 63900000 lines...\n",
      "Processed 64000000 lines...\n",
      "Processed 64100000 lines...\n",
      "Processed 64200000 lines...\n",
      "Processed 64300000 lines...\n",
      "Processed 64400000 lines...\n",
      "Processed 64500000 lines...\n",
      "Processed 64600000 lines...\n",
      "Processed 64700000 lines...\n",
      "Processed 64800000 lines...\n",
      "Processed 64900000 lines...\n",
      "Processed 65000000 lines...\n",
      "Processed 65100000 lines...\n",
      "Processed 65200000 lines...\n",
      "Processed 65300000 lines...\n",
      "Processed 65400000 lines...\n",
      "Processed 65500000 lines...\n",
      "Processed 65600000 lines...\n",
      "Processed 65700000 lines...\n",
      "Processed 65800000 lines...\n",
      "Processed 65900000 lines...\n",
      "Processed 66000000 lines...\n",
      "Processed 66100000 lines...\n",
      "Processed 66200000 lines...\n",
      "Processed 66300000 lines...\n",
      "Processed 66400000 lines...\n",
      "Processed 66500000 lines...\n",
      "Processed 66600000 lines...\n",
      "Processed 66700000 lines...\n",
      "Processed 66800000 lines...\n",
      "Processed 66900000 lines...\n",
      "Processed 67000000 lines...\n",
      "Processed 67100000 lines...\n",
      "Processed 67200000 lines...\n",
      "Processed 67300000 lines...\n",
      "Processed 67400000 lines...\n",
      "Processed 67500000 lines...\n",
      "Processed 67600000 lines...\n",
      "Processed 67700000 lines...\n",
      "Processed 67800000 lines...\n",
      "Processed 67900000 lines...\n",
      "Processed 68000000 lines...\n",
      "Processed 68100000 lines...\n",
      "Processed 68200000 lines...\n",
      "Processed 68300000 lines...\n",
      "Processed 68400000 lines...\n",
      "Processed 68500000 lines...\n",
      "Processed 68600000 lines...\n",
      "Processed 68700000 lines...\n",
      "Processed 68800000 lines...\n",
      "Processed 68900000 lines...\n",
      "Processed 69000000 lines...\n",
      "Processed 69100000 lines...\n",
      "Processed 69200000 lines...\n",
      "Processed 69300000 lines...\n",
      "Processed 69400000 lines...\n",
      "Processed 69500000 lines...\n",
      "Processed 69600000 lines...\n",
      "Processed 69700000 lines...\n",
      "Processed 69800000 lines...\n",
      "Processed 69900000 lines...\n",
      "Processed 70000000 lines...\n",
      "Processed 70100000 lines...\n",
      "Processed 70200000 lines...\n",
      "Processed 70300000 lines...\n",
      "Processed 70400000 lines...\n",
      "Processed 70500000 lines...\n",
      "Processed 70600000 lines...\n",
      "Processed 70700000 lines...\n",
      "Processed 70800000 lines...\n",
      "Processed 70900000 lines...\n",
      "Processed 71000000 lines...\n",
      "Processed 71100000 lines...\n",
      "Processed 71200000 lines...\n",
      "Processed 71300000 lines...\n",
      "Processed 71400000 lines...\n",
      "Processed 71500000 lines...\n",
      "Processed 71600000 lines...\n",
      "Processed 71700000 lines...\n",
      "Processed 71800000 lines...\n",
      "Processed 71900000 lines...\n",
      "Processed 72000000 lines...\n",
      "Processed 72100000 lines...\n",
      "Processed 72200000 lines...\n",
      "Processed 72300000 lines...\n",
      "Processed 72400000 lines...\n",
      "Processed 72500000 lines...\n",
      "Processed 72600000 lines...\n",
      "Processed 72700000 lines...\n",
      "Processed 72800000 lines...\n",
      "Processed 72900000 lines...\n",
      "Processed 73000000 lines...\n",
      "Processed 73100000 lines...\n",
      "Processed 73200000 lines...\n",
      "Processed 73300000 lines...\n",
      "Processed 73400000 lines...\n",
      "Processed 73500000 lines...\n",
      "Processed 73600000 lines...\n",
      "Processed 73700000 lines...\n",
      "Processed 73800000 lines...\n",
      "Processed 73900000 lines...\n",
      "Processed 74000000 lines...\n",
      "Processed 74100000 lines...\n",
      "Processed 74200000 lines...\n",
      "Processed 74300000 lines...\n",
      "Processed 74400000 lines...\n",
      "Processed 74500000 lines...\n",
      "Processed 74600000 lines...\n",
      "Processed 74700000 lines...\n",
      "Processed 74800000 lines...\n",
      "Processed 74900000 lines...\n",
      "Processed 75000000 lines...\n",
      "Processed 75100000 lines...\n",
      "Processed 75200000 lines...\n",
      "Processed 75300000 lines...\n",
      "Processed 75400000 lines...\n",
      "Processed 75500000 lines...\n",
      "Processed 75600000 lines...\n",
      "Processed 75700000 lines...\n",
      "Processed 75800000 lines...\n",
      "Processed 75900000 lines...\n",
      "Processed 76000000 lines...\n",
      "Processed 76100000 lines...\n",
      "Processed 76200000 lines...\n",
      "Processed 76300000 lines...\n",
      "Processed 76400000 lines...\n",
      "Processed 76500000 lines...\n",
      "Processed 76600000 lines...\n",
      "Processed 76700000 lines...\n",
      "Processed 76800000 lines...\n",
      "Processed 76900000 lines...\n",
      "Processed 77000000 lines...\n",
      "Processed 77100000 lines...\n",
      "Processed 77200000 lines...\n",
      "Processed 77300000 lines...\n",
      "Processed 77400000 lines...\n",
      "Processed 77500000 lines...\n",
      "Processed 77600000 lines...\n",
      "Processed 77700000 lines...\n",
      "Processed 77800000 lines...\n",
      "Processed 77900000 lines...\n",
      "Processed 78000000 lines...\n",
      "Processed 78100000 lines...\n",
      "Processed 78200000 lines...\n",
      "Processed 78300000 lines...\n",
      "Processed 78400000 lines...\n",
      "Processed 78500000 lines...\n",
      "Processed 78600000 lines...\n",
      "Processed 78700000 lines...\n",
      "Processed 78800000 lines...\n",
      "Processed 78900000 lines...\n",
      "Processed 79000000 lines...\n",
      "Processed 79100000 lines...\n",
      "Processed 79200000 lines...\n",
      "Processed 79300000 lines...\n",
      "Processed 79400000 lines...\n",
      "Processed 79500000 lines...\n",
      "Processed 79600000 lines...\n",
      "Processed 79700000 lines...\n",
      "Processed 79800000 lines...\n",
      "Processed 79900000 lines...\n",
      "Processed 80000000 lines...\n",
      "Processed 80100000 lines...\n",
      "Processed 80200000 lines...\n",
      "Processed 80300000 lines...\n",
      "Processed 80400000 lines...\n",
      "Processed 80500000 lines...\n",
      "Processed 80600000 lines...\n",
      "Processed 80700000 lines...\n",
      "Processed 80800000 lines...\n",
      "Processed 80900000 lines...\n",
      "Processed 81000000 lines...\n",
      "Processed 81100000 lines...\n",
      "Processed 81200000 lines...\n",
      "Processed 81300000 lines...\n",
      "Processed 81400000 lines...\n",
      "Processed 81500000 lines...\n",
      "Processed 81600000 lines...\n",
      "Processed 81700000 lines...\n",
      "Processed 81800000 lines...\n",
      "Processed 81900000 lines...\n",
      "Processed 82000000 lines...\n",
      "Processed 82100000 lines...\n",
      "Processed 82200000 lines...\n",
      "Processed 82300000 lines...\n",
      "Processed 82400000 lines...\n",
      "Processed 82500000 lines...\n",
      "Processed 82600000 lines...\n",
      "Processed 82700000 lines...\n",
      "Processed 82800000 lines...\n",
      "Processed 82900000 lines...\n",
      "Processed 83000000 lines...\n",
      "Processed 83100000 lines...\n",
      "Processed 83200000 lines...\n",
      "Processed 83300000 lines...\n",
      "Processed 83400000 lines...\n",
      "Processed 83500000 lines...\n",
      "Processed 83600000 lines...\n",
      "Processed 83700000 lines...\n",
      "Processed 83800000 lines...\n",
      "Processed 83900000 lines...\n",
      "Processed 84000000 lines...\n",
      "Processed 84100000 lines...\n",
      "Processed 84200000 lines...\n",
      "Processed 84300000 lines...\n",
      "Processed 84400000 lines...\n",
      "Processed 84500000 lines...\n",
      "Processed 84600000 lines...\n",
      "Processed 84700000 lines...\n",
      "Processed 84800000 lines...\n",
      "Processed 84900000 lines...\n",
      "Processed 85000000 lines...\n",
      "Processed 85100000 lines...\n",
      "Processed 85200000 lines...\n",
      "Processed 85300000 lines...\n",
      "Processed 85400000 lines...\n",
      "Processed 85500000 lines...\n",
      "Processed 85600000 lines...\n",
      "Processed 85700000 lines...\n",
      "Processed 85800000 lines...\n",
      "Processed 85900000 lines...\n",
      "Processed 86000000 lines...\n",
      "Processed 86100000 lines...\n",
      "Processed 86200000 lines...\n",
      "Processed 86300000 lines...\n",
      "Processed 86400000 lines...\n",
      "Processed 86500000 lines...\n",
      "Processed 86600000 lines...\n",
      "Processed 86700000 lines...\n",
      "Processed 86800000 lines...\n",
      "Processed 86900000 lines...\n",
      "Processed 87000000 lines...\n",
      "Processed 87100000 lines...\n",
      "Processed 87200000 lines...\n",
      "Processed 87300000 lines...\n",
      "Processed 87400000 lines...\n",
      "Processed 87500000 lines...\n",
      "Processed 87600000 lines...\n",
      "Processed 87700000 lines...\n",
      "Processed 87800000 lines...\n",
      "Processed 87900000 lines...\n",
      "Processed 88000000 lines...\n",
      "Processed 88100000 lines...\n",
      "Processed 88200000 lines...\n",
      "Processed 88300000 lines...\n",
      "Processed 88400000 lines...\n",
      "Processed 88500000 lines...\n",
      "Processed 88600000 lines...\n",
      "Processed 88700000 lines...\n",
      "Processed 88800000 lines...\n",
      "Processed 88900000 lines...\n",
      "Processed 89000000 lines...\n",
      "Processed 89100000 lines...\n",
      "Processed 89200000 lines...\n",
      "Processed 89300000 lines...\n",
      "Processed 89400000 lines...\n",
      "Processed 89500000 lines...\n",
      "Processed 89600000 lines...\n",
      "Processed 89700000 lines...\n",
      "Processed 89800000 lines...\n",
      "Processed 89900000 lines...\n",
      "Processed 90000000 lines...\n",
      "Processed 90100000 lines...\n",
      "Processed 90200000 lines...\n",
      "Processed 90300000 lines...\n",
      "Processed 90400000 lines...\n",
      "Processed 90500000 lines...\n",
      "Processed 90600000 lines...\n",
      "Processed 90700000 lines...\n",
      "Processed 90800000 lines...\n",
      "Processed 90900000 lines...\n",
      "Processed 91000000 lines...\n",
      "Processed 91100000 lines...\n",
      "Processed 91200000 lines...\n",
      "Processed 91300000 lines...\n",
      "Processed 91400000 lines...\n",
      "Processed 91500000 lines...\n",
      "Processed 91600000 lines...\n",
      "Processed 91700000 lines...\n",
      "Processed 91800000 lines...\n",
      "Processed 91900000 lines...\n",
      "Processed 92000000 lines...\n",
      "Processed 92100000 lines...\n",
      "Processed 92200000 lines...\n",
      "Processed 92300000 lines...\n",
      "Processed 92400000 lines...\n",
      "Processed 92500000 lines...\n",
      "Processed 92600000 lines...\n",
      "Processed 92700000 lines...\n",
      "Processed 92800000 lines...\n",
      "Processed 92900000 lines...\n",
      "Processed 93000000 lines...\n",
      "Processed 93100000 lines...\n",
      "Processed 93200000 lines...\n",
      "Processed 93300000 lines...\n",
      "Processed 93400000 lines...\n",
      "Processed 93500000 lines...\n",
      "Processed 93600000 lines...\n",
      "Processed 93700000 lines...\n",
      "Processed 93800000 lines...\n",
      "Processed 93900000 lines...\n",
      "Processed 94000000 lines...\n",
      "Processed 94100000 lines...\n",
      "Processed 94200000 lines...\n",
      "Processed 94300000 lines...\n",
      "Processed 94400000 lines...\n",
      "Processed 94500000 lines...\n",
      "Processed 94600000 lines...\n",
      "Processed 94700000 lines...\n",
      "Processed 94800000 lines...\n",
      "Processed 94900000 lines...\n",
      "Processed 95000000 lines...\n",
      "Processed 95100000 lines...\n",
      "Processed 95200000 lines...\n",
      "Processed 95300000 lines...\n",
      "Processed 95400000 lines...\n",
      "Processed 95500000 lines...\n",
      "Processed 95600000 lines...\n",
      "Processed 95700000 lines...\n",
      "Processed 95800000 lines...\n",
      "Processed 95900000 lines...\n",
      "Processed 96000000 lines...\n",
      "Processed 96100000 lines...\n",
      "Processed 96200000 lines...\n",
      "Processed 96300000 lines...\n",
      "Processed 96400000 lines...\n",
      "Processed 96500000 lines...\n",
      "Processed 96600000 lines...\n",
      "Processed 96700000 lines...\n",
      "Processed 96800000 lines...\n",
      "Processed 96900000 lines...\n",
      "Processed 97000000 lines...\n",
      "Processed 97100000 lines...\n",
      "Processed 97200000 lines...\n",
      "Processed 97300000 lines...\n",
      "Processed 97400000 lines...\n",
      "Processed 97500000 lines...\n",
      "Processed 97600000 lines...\n",
      "Processed 97700000 lines...\n",
      "Processed 97800000 lines...\n",
      "Processed 97900000 lines...\n",
      "Processed 98000000 lines...\n",
      "Processed 98100000 lines...\n",
      "Processed 98200000 lines...\n",
      "Processed 98300000 lines...\n",
      "Processed 98400000 lines...\n",
      "Processed 98500000 lines...\n",
      "Processed 98600000 lines...\n",
      "Processed 98700000 lines...\n",
      "Processed 98800000 lines...\n",
      "Processed 98900000 lines...\n",
      "Processed 99000000 lines...\n",
      "Processed 99100000 lines...\n",
      "Processed 99200000 lines...\n",
      "Processed 99300000 lines...\n",
      "Processed 99400000 lines...\n",
      "Processed 99500000 lines...\n",
      "Processed 99600000 lines...\n",
      "Processed 99700000 lines...\n",
      "Processed 99800000 lines...\n",
      "Processed 99900000 lines...\n",
      "Processed 100000000 lines...\n",
      "Processed 100100000 lines...\n",
      "Processed 100200000 lines...\n",
      "Processed 100300000 lines...\n",
      "Processed 100400000 lines...\n",
      "Processed 100500000 lines...\n",
      "Processed 100600000 lines...\n",
      "Processed 100700000 lines...\n",
      "Processed 100800000 lines...\n",
      "Processed 100900000 lines...\n",
      "Processed 101000000 lines...\n",
      "Processed 101100000 lines...\n",
      "Processed 101200000 lines...\n",
      "Processed 101300000 lines...\n",
      "Processed 101400000 lines...\n",
      "Processed 101500000 lines...\n",
      "Processed 101600000 lines...\n",
      "Processed 101700000 lines...\n",
      "Processed 101800000 lines...\n",
      "Processed 101900000 lines...\n",
      "Processed 102000000 lines...\n",
      "Processed 102100000 lines...\n",
      "Processed 102200000 lines...\n",
      "Processed 102300000 lines...\n",
      "Processed 102400000 lines...\n",
      "Processed 102500000 lines...\n",
      "Processed 102600000 lines...\n",
      "Processed 102700000 lines...\n",
      "Processed 102800000 lines...\n",
      "Processed 102900000 lines...\n",
      "Processed 103000000 lines...\n",
      "Processed 103100000 lines...\n",
      "Processed 103200000 lines...\n",
      "Processed 103300000 lines...\n",
      "Processed 103400000 lines...\n",
      "Processed 103500000 lines...\n",
      "Processed 103600000 lines...\n",
      "Processed 103700000 lines...\n",
      "Processed 103800000 lines...\n",
      "Processed 103900000 lines...\n",
      "Processed 104000000 lines...\n",
      "Processed 104100000 lines...\n",
      "Processed 104200000 lines...\n",
      "Processed 104300000 lines...\n",
      "Processed 104400000 lines...\n",
      "Processed 104500000 lines...\n",
      "Processed 104600000 lines...\n",
      "Processed 104700000 lines...\n",
      "Processed 104800000 lines...\n",
      "Processed 104900000 lines...\n",
      "Processed 105000000 lines...\n",
      "Processed 105100000 lines...\n",
      "Processed 105200000 lines...\n",
      "Processed 105300000 lines...\n",
      "Processed 105400000 lines...\n",
      "Processed 105500000 lines...\n",
      "Processed 105600000 lines...\n",
      "Processed 105700000 lines...\n",
      "Processed 105800000 lines...\n",
      "Processed 105900000 lines...\n",
      "Processed 106000000 lines...\n",
      "Processed 106100000 lines...\n",
      "Processed 106200000 lines...\n",
      "Processed 106300000 lines...\n",
      "Processed 106400000 lines...\n",
      "Processed 106500000 lines...\n",
      "Processed 106600000 lines...\n",
      "Processed 106700000 lines...\n",
      "Processed 106800000 lines...\n",
      "Processed 106900000 lines...\n",
      "Processed 107000000 lines...\n",
      "Processed 107100000 lines...\n",
      "Processed 107200000 lines...\n",
      "Processed 107300000 lines...\n",
      "Processed 107400000 lines...\n",
      "Processed 107500000 lines...\n",
      "Processed 107600000 lines...\n",
      "Processed 107700000 lines...\n",
      "Processed 107800000 lines...\n",
      "Processed 107900000 lines...\n",
      "Processed 108000000 lines...\n",
      "Processed 108100000 lines...\n",
      "Processed 108200000 lines...\n",
      "Processed 108300000 lines...\n",
      "Processed 108400000 lines...\n",
      "Processed 108500000 lines...\n",
      "Processed 108600000 lines...\n",
      "Processed 108700000 lines...\n",
      "Processed 108800000 lines...\n",
      "Processed 108900000 lines...\n",
      "Processed 109000000 lines...\n",
      "Processed 109100000 lines...\n",
      "Processed 109200000 lines...\n",
      "Processed 109300000 lines...\n",
      "Processed 109400000 lines...\n",
      "Processed 109500000 lines...\n",
      "Processed 109600000 lines...\n",
      "Processed 109700000 lines...\n",
      "Processed 109800000 lines...\n",
      "Processed 109900000 lines...\n",
      "Processed 110000000 lines...\n",
      "Processed 110100000 lines...\n",
      "Processed 110200000 lines...\n",
      "Processed 110300000 lines...\n",
      "Processed 110400000 lines...\n",
      "Processed 110500000 lines...\n",
      "Processed 110600000 lines...\n",
      "Processed 110700000 lines...\n",
      "Processed 110800000 lines...\n",
      "Processed 110900000 lines...\n",
      "Processed 111000000 lines...\n",
      "Processed 111100000 lines...\n",
      "Processed 111200000 lines...\n",
      "Processed 111300000 lines...\n",
      "Processed 111400000 lines...\n",
      "Processed 111500000 lines...\n",
      "Processed 111600000 lines...\n",
      "Processed 111700000 lines...\n",
      "Processed 111800000 lines...\n",
      "Processed 111900000 lines...\n",
      "Processed 112000000 lines...\n",
      "Processed 112100000 lines...\n",
      "Processed 112200000 lines...\n",
      "Processed 112300000 lines...\n",
      "Processed 112400000 lines...\n",
      "Processed 112500000 lines...\n",
      "Processed 112600000 lines...\n",
      "Processed 112700000 lines...\n",
      "Processed 112800000 lines...\n",
      "Processed 112900000 lines...\n",
      "Processed 113000000 lines...\n",
      "Processed 113100000 lines...\n",
      "Processed 113200000 lines...\n",
      "Processed 113300000 lines...\n",
      "Processed 113400000 lines...\n",
      "Processed 113500000 lines...\n",
      "Processed 113600000 lines...\n",
      "Processed 113700000 lines...\n",
      "Processed 113800000 lines...\n",
      "Processed 113900000 lines...\n",
      "Processed 114000000 lines...\n",
      "Processed 114100000 lines...\n",
      "Processed 114200000 lines...\n",
      "Processed 114300000 lines...\n",
      "Processed 114400000 lines...\n",
      "Processed 114500000 lines...\n",
      "Processed 114600000 lines...\n",
      "Processed 114700000 lines...\n",
      "Processed 114800000 lines...\n",
      "Processed 114900000 lines...\n",
      "Processed 115000000 lines...\n",
      "Processed 115100000 lines...\n",
      "Processed 115200000 lines...\n",
      "Processed 115300000 lines...\n",
      "Processed 115400000 lines...\n",
      "Processed 115500000 lines...\n",
      "Processed 115600000 lines...\n",
      "Processed 115700000 lines...\n",
      "Processed 115800000 lines...\n",
      "Processed 115900000 lines...\n",
      "Processed 116000000 lines...\n",
      "Processed 116100000 lines...\n",
      "Processed 116200000 lines...\n",
      "Processed 116300000 lines...\n",
      "Processed 116400000 lines...\n",
      "Processed 116500000 lines...\n",
      "Processed 116600000 lines...\n",
      "Processed 116700000 lines...\n",
      "Processed 116800000 lines...\n",
      "Processed 116900000 lines...\n",
      "Processed 117000000 lines...\n",
      "Processed 117100000 lines...\n",
      "Processed 117200000 lines...\n",
      "Processed 117300000 lines...\n",
      "Processed 117400000 lines...\n",
      "Processed 117500000 lines...\n",
      "Processed 117600000 lines...\n",
      "Processed 117700000 lines...\n",
      "Processed 117800000 lines...\n",
      "Processed 117900000 lines...\n",
      "Processed 118000000 lines...\n",
      "Processed 118100000 lines...\n",
      "Processed 118200000 lines...\n",
      "Processed 118300000 lines...\n",
      "Processed 118400000 lines...\n",
      "Processed 118500000 lines...\n",
      "Processed 118600000 lines...\n",
      "Processed 118700000 lines...\n",
      "Processed 118800000 lines...\n",
      "Processed 118900000 lines...\n",
      "Processed 119000000 lines...\n",
      "Processed 119100000 lines...\n",
      "Processed 119200000 lines...\n",
      "Processed 119300000 lines...\n",
      "Processed 119400000 lines...\n",
      "Processed 119500000 lines...\n",
      "Processed 119600000 lines...\n",
      "Processed 119700000 lines...\n",
      "Processed 119800000 lines...\n",
      "Processed 119900000 lines...\n",
      "Processed 120000000 lines...\n",
      "Processed 120100000 lines...\n",
      "Processed 120200000 lines...\n",
      "Processed 120300000 lines...\n",
      "Processed 120400000 lines...\n",
      "Processed 120500000 lines...\n",
      "Processed 120600000 lines...\n",
      "Processed 120700000 lines...\n",
      "Processed 120800000 lines...\n",
      "Processed 120900000 lines...\n",
      "Processed 121000000 lines...\n",
      "Processed 121100000 lines...\n",
      "Processed 121200000 lines...\n",
      "Processed 121300000 lines...\n",
      "Processed 121400000 lines...\n",
      "Processed 121500000 lines...\n",
      "Processed 121600000 lines...\n",
      "Processed 121700000 lines...\n",
      "Processed 121800000 lines...\n",
      "Processed 121900000 lines...\n",
      "Processed 122000000 lines...\n",
      "Processed 122100000 lines...\n",
      "Processed 122200000 lines...\n",
      "Processed 122300000 lines...\n",
      "Processed 122400000 lines...\n",
      "Processed 122500000 lines...\n",
      "Processed 122600000 lines...\n",
      "Processed 122700000 lines...\n",
      "Processed 122800000 lines...\n",
      "Processed 122900000 lines...\n",
      "Processed 123000000 lines...\n",
      "Processed 123100000 lines...\n",
      "Processed 123200000 lines...\n",
      "Processed 123300000 lines...\n",
      "Processed 123400000 lines...\n",
      "Processed 123500000 lines...\n",
      "Processed 123600000 lines...\n",
      "Processed 123700000 lines...\n",
      "Processed 123800000 lines...\n",
      "Processed 123900000 lines...\n",
      "Processed 124000000 lines...\n",
      "Processed 124100000 lines...\n",
      "Processed 124200000 lines...\n",
      "Processed 124300000 lines...\n",
      "Processed 124400000 lines...\n",
      "Processed 124500000 lines...\n",
      "Processed 124600000 lines...\n",
      "Processed 124700000 lines...\n",
      "Processed 124800000 lines...\n",
      "Processed 124900000 lines...\n",
      "Processed 125000000 lines...\n",
      "Processed 125100000 lines...\n",
      "Processed 125200000 lines...\n",
      "Processed 125300000 lines...\n",
      "Processed 125400000 lines...\n",
      "Processed 125500000 lines...\n",
      "Processed 125600000 lines...\n",
      "Processed 125700000 lines...\n",
      "Processed 125800000 lines...\n",
      "Processed 125900000 lines...\n",
      "Processed 126000000 lines...\n",
      "Processed 126100000 lines...\n",
      "Processed 126200000 lines...\n",
      "Processed 126300000 lines...\n",
      "Processed 126400000 lines...\n",
      "Processed 126500000 lines...\n",
      "Processed 126600000 lines...\n",
      "Processed 126700000 lines...\n",
      "Processed 126800000 lines...\n",
      "Processed 126900000 lines...\n",
      "Processed 127000000 lines...\n",
      "Processed 127100000 lines...\n",
      "Processed 127200000 lines...\n",
      "Processed 127300000 lines...\n",
      "Processed 127400000 lines...\n",
      "Processed 127500000 lines...\n",
      "Processed 127600000 lines...\n",
      "Processed 127700000 lines...\n",
      "Processed 127800000 lines...\n",
      "Processed 127900000 lines...\n",
      "Processed 128000000 lines...\n",
      "Processed 128100000 lines...\n",
      "Processed 128200000 lines...\n",
      "Processed 128300000 lines...\n",
      "Processed 128400000 lines...\n",
      "Processed 128500000 lines...\n",
      "Processed 128600000 lines...\n",
      "Processed 128700000 lines...\n",
      "Processed 128800000 lines...\n",
      "Processed 128900000 lines...\n",
      "Processed 129000000 lines...\n",
      "Processed 129100000 lines...\n",
      "Processed 129200000 lines...\n",
      "Processed 129300000 lines...\n",
      "Processed 129400000 lines...\n",
      "Processed 129500000 lines...\n",
      "Processed 129600000 lines...\n",
      "Processed 129700000 lines...\n",
      "Processed 129800000 lines...\n",
      "Processed 129900000 lines...\n",
      "Processed 130000000 lines...\n",
      "Processed 130100000 lines...\n",
      "Processed 130200000 lines...\n",
      "Processed 130300000 lines...\n",
      "Processed 130400000 lines...\n",
      "Processed 130500000 lines...\n",
      "Processed 130600000 lines...\n",
      "Processed 130700000 lines...\n",
      "Processed 130800000 lines...\n",
      "Processed 130900000 lines...\n",
      "Processed 131000000 lines...\n",
      "Processed 131100000 lines...\n",
      "Processed 131200000 lines...\n",
      "Processed 131300000 lines...\n",
      "Processed 131400000 lines...\n",
      "Processed 131500000 lines...\n",
      "Processed 131600000 lines...\n",
      "Processed 131700000 lines...\n",
      "Processed 131800000 lines...\n",
      "Processed 131900000 lines...\n",
      "Processed 132000000 lines...\n",
      "Processed 132100000 lines...\n",
      "Processed 132200000 lines...\n",
      "Processed 132300000 lines...\n",
      "Processed 132400000 lines...\n",
      "Processed 132500000 lines...\n",
      "Processed 132600000 lines...\n",
      "Processed 132700000 lines...\n",
      "Processed 132800000 lines...\n",
      "Processed 132900000 lines...\n",
      "Processed 133000000 lines...\n",
      "Processed 133100000 lines...\n",
      "Processed 133200000 lines...\n",
      "Processed 133300000 lines...\n",
      "Processed 133400000 lines...\n",
      "Processed 133500000 lines...\n",
      "Processed 133600000 lines...\n",
      "Processed 133700000 lines...\n",
      "Processed 133800000 lines...\n",
      "Processed 133900000 lines...\n",
      "Processed 134000000 lines...\n",
      "Processed 134100000 lines...\n",
      "Processed 134200000 lines...\n",
      "Processed 134300000 lines...\n",
      "Processed 134400000 lines...\n",
      "Processed 134500000 lines...\n",
      "Processed 134600000 lines...\n",
      "Processed 134700000 lines...\n",
      "Processed 134800000 lines...\n",
      "Processed 134900000 lines...\n",
      "Processed 135000000 lines...\n",
      "Processed 135100000 lines...\n",
      "Processed 135200000 lines...\n",
      "Processed 135300000 lines...\n",
      "Processed 135400000 lines...\n",
      "Processed 135500000 lines...\n",
      "Processed 135600000 lines...\n",
      "Processed 135700000 lines...\n",
      "Processed 135800000 lines...\n",
      "Processed 135900000 lines...\n",
      "Processed 136000000 lines...\n",
      "Processed 136100000 lines...\n",
      "Processed 136200000 lines...\n",
      "Processed 136300000 lines...\n",
      "Processed 136400000 lines...\n",
      "Processed 136500000 lines...\n",
      "Processed 136600000 lines...\n",
      "Processed 136700000 lines...\n",
      "Processed 136800000 lines...\n",
      "Processed 136900000 lines...\n",
      "Processed 137000000 lines...\n",
      "Processed 137100000 lines...\n",
      "Processed 137200000 lines...\n",
      "Processed 137300000 lines...\n",
      "Processed 137400000 lines...\n",
      "Processed 137500000 lines...\n",
      "Processed 137600000 lines...\n",
      "Processed 137700000 lines...\n",
      "Processed 137800000 lines...\n",
      "Processed 137900000 lines...\n",
      "Processed 138000000 lines...\n",
      "Processed 138100000 lines...\n",
      "Processed 138200000 lines...\n",
      "Processed 138300000 lines...\n",
      "Processed 138400000 lines...\n",
      "Processed 138500000 lines...\n",
      "Processed 138600000 lines...\n",
      "Processed 138700000 lines...\n",
      "Processed 138800000 lines...\n",
      "Processed 138900000 lines...\n",
      "Processed 139000000 lines...\n",
      "Processed 139100000 lines...\n",
      "Processed 139200000 lines...\n",
      "Processed 139300000 lines...\n",
      "Processed 139400000 lines...\n",
      "Processed 139500000 lines...\n",
      "Processed 139600000 lines...\n",
      "Processed 139700000 lines...\n",
      "Processed 139800000 lines...\n",
      "Processed 139900000 lines...\n",
      "Processed 140000000 lines...\n",
      "Processed 140100000 lines...\n",
      "Processed 140200000 lines...\n",
      "Processed 140300000 lines...\n",
      "Processed 140400000 lines...\n",
      "Processed 140500000 lines...\n",
      "Processed 140600000 lines...\n",
      "Processed 140700000 lines...\n",
      "Processed 140800000 lines...\n",
      "Processed 140900000 lines...\n",
      "Processed 141000000 lines...\n",
      "Processed 141100000 lines...\n",
      "Processed 141200000 lines...\n",
      "Processed 141300000 lines...\n",
      "Processed 141400000 lines...\n",
      "Processed 141500000 lines...\n",
      "Processed 141600000 lines...\n",
      "Processed 141700000 lines...\n",
      "Processed 141800000 lines...\n",
      "Processed 141900000 lines...\n",
      "Processed 142000000 lines...\n",
      "Processed 142100000 lines...\n",
      "Processed 142200000 lines...\n",
      "Processed 142300000 lines...\n",
      "Processed 142400000 lines...\n",
      "Processed 142500000 lines...\n",
      "Processed 142600000 lines...\n",
      "Processed 142700000 lines...\n",
      "Processed 142800000 lines...\n",
      "Processed 142900000 lines...\n",
      "Processed 143000000 lines...\n",
      "Processed 143100000 lines...\n",
      "Processed 143200000 lines...\n",
      "Processed 143300000 lines...\n",
      "Processed 143400000 lines...\n",
      "Processed 143500000 lines...\n",
      "Processed 143600000 lines...\n",
      "Processed 143700000 lines...\n",
      "Processed 143800000 lines...\n",
      "Processed 143900000 lines...\n",
      "Processed 144000000 lines...\n",
      "Processed 144100000 lines...\n",
      "Processed 144200000 lines...\n",
      "Processed 144300000 lines...\n",
      "Processed 144400000 lines...\n",
      "Processed 144500000 lines...\n",
      "Processed 144600000 lines...\n",
      "Processed 144700000 lines...\n",
      "Processed 144800000 lines...\n",
      "Processed 144900000 lines...\n",
      "Processed 145000000 lines...\n",
      "Processed 145100000 lines...\n",
      "Processed 145200000 lines...\n",
      "Processed 145300000 lines...\n",
      "Processed 145400000 lines...\n",
      "Processed 145500000 lines...\n",
      "Processed 145600000 lines...\n",
      "Processed 145700000 lines...\n",
      "Processed 145800000 lines...\n",
      "Processed 145900000 lines...\n",
      "Processed 146000000 lines...\n",
      "Processed 146100000 lines...\n",
      "Processed 146200000 lines...\n",
      "Processed 146300000 lines...\n",
      "Processed 146400000 lines...\n",
      "Processed 146500000 lines...\n",
      "Processed 146600000 lines...\n",
      "Processed 146700000 lines...\n",
      "Processed 146800000 lines...\n",
      "Processed 146900000 lines...\n",
      "Processed 147000000 lines...\n",
      "Processed 147100000 lines...\n",
      "Processed 147200000 lines...\n",
      "Processed 147300000 lines...\n",
      "Processed 147400000 lines...\n",
      "Processed 147500000 lines...\n",
      "Processed 147600000 lines...\n",
      "Processed 147700000 lines...\n",
      "Processed 147800000 lines...\n",
      "Processed 147900000 lines...\n",
      "Processed 148000000 lines...\n",
      "Processed 148100000 lines...\n",
      "Processed 148200000 lines...\n",
      "Processed 148300000 lines...\n",
      "Processed 148400000 lines...\n",
      "Processed 148500000 lines...\n",
      "Processed 148600000 lines...\n",
      "Processed 148700000 lines...\n",
      "Processed 148800000 lines...\n",
      "Processed 148900000 lines...\n",
      "Processed 149000000 lines...\n",
      "Processed 149100000 lines...\n",
      "Processed 149200000 lines...\n",
      "Processed 149300000 lines...\n",
      "Processed 149400000 lines...\n",
      "Processed 149500000 lines...\n",
      "Processed 149600000 lines...\n",
      "Processed 149700000 lines...\n",
      "Processed 149800000 lines...\n",
      "Processed 149900000 lines...\n",
      "Processed 150000000 lines...\n",
      "Processed 150100000 lines...\n",
      "Processed 150200000 lines...\n",
      "Processed 150300000 lines...\n",
      "Processed 150400000 lines...\n",
      "Processed 150500000 lines...\n",
      "Processed 150600000 lines...\n",
      "Processed 150700000 lines...\n",
      "Processed 150800000 lines...\n",
      "Processed 150900000 lines...\n",
      "Processed 151000000 lines...\n",
      "Processed 151100000 lines...\n",
      "Processed 151200000 lines...\n",
      "Processed 151300000 lines...\n",
      "Processed 151400000 lines...\n",
      "Processed 151500000 lines...\n",
      "Processed 151600000 lines...\n",
      "Processed 151700000 lines...\n",
      "Processed 151800000 lines...\n",
      "Processed 151900000 lines...\n",
      "Processed 152000000 lines...\n",
      "Processed 152100000 lines...\n",
      "Processed 152200000 lines...\n",
      "Processed 152300000 lines...\n",
      "Processed 152400000 lines...\n",
      "Processed 152500000 lines...\n",
      "Processed 152600000 lines...\n",
      "Processed 152700000 lines...\n",
      "Processed 152800000 lines...\n",
      "Processed 152900000 lines...\n",
      "Processed 153000000 lines...\n",
      "Processed 153100000 lines...\n",
      "Processed 153200000 lines...\n",
      "Processed 153300000 lines...\n",
      "Processed 153400000 lines...\n",
      "Processed 153500000 lines...\n",
      "Processed 153600000 lines...\n",
      "Processed 153700000 lines...\n",
      "Processed 153800000 lines...\n",
      "Processed 153900000 lines...\n",
      "Processed 154000000 lines...\n",
      "Processed 154100000 lines...\n",
      "Processed 154200000 lines...\n",
      "Processed 154300000 lines...\n",
      "Processed 154400000 lines...\n",
      "Processed 154500000 lines...\n",
      "Processed 154600000 lines...\n",
      "Processed 154700000 lines...\n",
      "Processed 154800000 lines...\n",
      "Processed 154900000 lines...\n",
      "Processed 155000000 lines...\n",
      "Processed 155100000 lines...\n",
      "Processed 155200000 lines...\n",
      "Processed 155300000 lines...\n",
      "Processed 155400000 lines...\n",
      "Processed 155500000 lines...\n",
      "Processed 155600000 lines...\n",
      "Processed 155700000 lines...\n",
      "Processed 155800000 lines...\n",
      "Processed 155900000 lines...\n",
      "Processed 156000000 lines...\n",
      "Processed 156100000 lines...\n",
      "Processed 156200000 lines...\n",
      "Processed 156300000 lines...\n",
      "Processed 156400000 lines...\n",
      "Processed 156500000 lines...\n",
      "Processed 156600000 lines...\n",
      "Processed 156700000 lines...\n",
      "Processed 156800000 lines...\n",
      "Processed 156900000 lines...\n",
      "Processed 157000000 lines...\n",
      "Processed 157100000 lines...\n",
      "Processed 157200000 lines...\n",
      "Processed 157300000 lines...\n",
      "Processed 157400000 lines...\n",
      "Processed 157500000 lines...\n",
      "Processed 157600000 lines...\n",
      "Processed 157700000 lines...\n",
      "Processed 157800000 lines...\n",
      "Processed 157900000 lines...\n",
      "Processed 158000000 lines...\n",
      "Processed 158100000 lines...\n",
      "Processed 158200000 lines...\n",
      "Processed 158300000 lines...\n",
      "Processed 158400000 lines...\n",
      "Processed 158500000 lines...\n",
      "Processed 158600000 lines...\n",
      "Processed 158700000 lines...\n",
      "Processed 158800000 lines...\n",
      "Processed 158900000 lines...\n",
      "Processed 159000000 lines...\n",
      "Processed 159100000 lines...\n",
      "Processed 159200000 lines...\n",
      "Processed 159300000 lines...\n",
      "Processed 159400000 lines...\n",
      "Processed 159500000 lines...\n",
      "Processed 159600000 lines...\n",
      "Processed 159700000 lines...\n",
      "Processed 159800000 lines...\n",
      "Processed 159900000 lines...\n",
      "Processed 160000000 lines...\n",
      "Processed 160100000 lines...\n",
      "Processed 160200000 lines...\n",
      "Processed 160300000 lines...\n",
      "Processed 160400000 lines...\n",
      "Processed 160500000 lines...\n",
      "Processed 160600000 lines...\n",
      "Processed 160700000 lines...\n",
      "Processed 160800000 lines...\n",
      "Processed 160900000 lines...\n",
      "Processed 161000000 lines...\n",
      "Processed 161100000 lines...\n",
      "Processed 161200000 lines...\n",
      "Processed 161300000 lines...\n",
      "Processed 161400000 lines...\n",
      "Processed 161500000 lines...\n",
      "Processed 161600000 lines...\n",
      "Processed 161700000 lines...\n",
      "Processed 161800000 lines...\n",
      "Processed 161900000 lines...\n",
      "Processed 162000000 lines...\n",
      "Processed 162100000 lines...\n",
      "Processed 162200000 lines...\n",
      "Processed 162300000 lines...\n",
      "Processed 162400000 lines...\n",
      "Processed 162500000 lines...\n",
      "Processed 162600000 lines...\n",
      "Processed 162700000 lines...\n",
      "Processed 162800000 lines...\n",
      "Processed 162900000 lines...\n",
      "Processed 163000000 lines...\n",
      "Processed 163100000 lines...\n",
      "Processed 163200000 lines...\n",
      "Processed 163300000 lines...\n",
      "Processed 163400000 lines...\n",
      "Processed 163500000 lines...\n",
      "Processed 163600000 lines...\n",
      "Processed 163700000 lines...\n",
      "Processed 163800000 lines...\n",
      "Processed 163900000 lines...\n",
      "Processed 164000000 lines...\n",
      "Processed 164100000 lines...\n",
      "Processed 164200000 lines...\n",
      "Processed 164300000 lines...\n",
      "Processed 164400000 lines...\n",
      "Processed 164500000 lines...\n",
      "Processed 164600000 lines...\n",
      "Processed 164700000 lines...\n",
      "Processed 164800000 lines...\n",
      "Processed 164900000 lines...\n",
      "Processed 165000000 lines...\n",
      "Processed 165100000 lines...\n",
      "Processed 165200000 lines...\n",
      "Processed 165300000 lines...\n",
      "Processed 165400000 lines...\n",
      "Processed 165500000 lines...\n",
      "Processed 165600000 lines...\n",
      "Processed 165700000 lines...\n",
      "Processed 165800000 lines...\n",
      "Processed 165900000 lines...\n",
      "Processed 166000000 lines...\n",
      "Processed 166100000 lines...\n",
      "Processed 166200000 lines...\n",
      "Processed 166300000 lines...\n",
      "Processed 166400000 lines...\n",
      "Processed 166500000 lines...\n",
      "Processed 166600000 lines...\n",
      "Processed 166700000 lines...\n",
      "Processed 166800000 lines...\n",
      "Processed 166900000 lines...\n",
      "Processed 167000000 lines...\n",
      "Processed 167100000 lines...\n",
      "Processed 167200000 lines...\n",
      "Processed 167300000 lines...\n",
      "Processed 167400000 lines...\n",
      "Processed 167500000 lines...\n",
      "Processed 167600000 lines...\n",
      "Processed 167700000 lines...\n",
      "Processed 167800000 lines...\n",
      "Processed 167900000 lines...\n",
      "Processed 168000000 lines...\n",
      "Processed 168100000 lines...\n",
      "Processed 168200000 lines...\n",
      "Processed 168300000 lines...\n",
      "Processed 168400000 lines...\n",
      "Processed 168500000 lines...\n",
      "Processed 168600000 lines...\n",
      "Processed 168700000 lines...\n",
      "Processed 168800000 lines...\n",
      "Processed 168900000 lines...\n",
      "Processed 169000000 lines...\n",
      "Processed 169100000 lines...\n",
      "Processed 169200000 lines...\n",
      "Processed 169300000 lines...\n",
      "Processed 169400000 lines...\n",
      "Processed 169500000 lines...\n",
      "Processed 169600000 lines...\n",
      "Processed 169700000 lines...\n",
      "Processed 169800000 lines...\n",
      "Processed 169900000 lines...\n",
      "Processed 170000000 lines...\n",
      "Processed 170100000 lines...\n",
      "Processed 170200000 lines...\n",
      "Processed 170300000 lines...\n",
      "Processed 170400000 lines...\n",
      "Processed 170500000 lines...\n",
      "Processed 170600000 lines...\n",
      "Processed 170700000 lines...\n",
      "Processed 170800000 lines...\n",
      "Processed 170900000 lines...\n",
      "Processed 171000000 lines...\n",
      "Processed 171100000 lines...\n",
      "Processed 171200000 lines...\n",
      "Processed 171300000 lines...\n",
      "Processed 171400000 lines...\n",
      "Processed 171500000 lines...\n",
      "Processed 171600000 lines...\n",
      "Processed 171700000 lines...\n",
      "Processed 171800000 lines...\n",
      "Processed 171900000 lines...\n",
      "Processed 172000000 lines...\n",
      "Processed 172100000 lines...\n",
      "Processed 172200000 lines...\n",
      "Processed 172300000 lines...\n",
      "Processed 172400000 lines...\n",
      "Processed 172500000 lines...\n",
      "Processed 172600000 lines...\n",
      "Processed 172700000 lines...\n",
      "Processed 172800000 lines...\n",
      "Processed 172900000 lines...\n",
      "Processed 173000000 lines...\n",
      "Processed 173100000 lines...\n",
      "Processed 173200000 lines...\n",
      "Processed 173300000 lines...\n",
      "Processed 173400000 lines...\n",
      "Processed 173500000 lines...\n",
      "Processed 173600000 lines...\n",
      "Processed 173700000 lines...\n",
      "Processed 173800000 lines...\n",
      "Processed 173900000 lines...\n",
      "Processed 174000000 lines...\n",
      "Processed 174100000 lines...\n",
      "Processed 174200000 lines...\n",
      "Processed 174300000 lines...\n",
      "Processed 174400000 lines...\n",
      "Processed 174500000 lines...\n",
      "Processed 174600000 lines...\n",
      "Processed 174700000 lines...\n",
      "Processed 174800000 lines...\n",
      "Processed 174900000 lines...\n",
      "Processed 175000000 lines...\n",
      "Processed 175100000 lines...\n",
      "Processed 175200000 lines...\n",
      "Processed 175300000 lines...\n",
      "Processed 175400000 lines...\n",
      "Processed 175500000 lines...\n",
      "Processed 175600000 lines...\n",
      "Processed 175700000 lines...\n",
      "Processed 175800000 lines...\n",
      "Processed 175900000 lines...\n",
      "Processed 176000000 lines...\n",
      "Processed 176100000 lines...\n",
      "Processed 176200000 lines...\n",
      "Processed 176300000 lines...\n",
      "Processed 176400000 lines...\n",
      "Processed 176500000 lines...\n",
      "Processed 176600000 lines...\n",
      "Processed 176700000 lines...\n",
      "Processed 176800000 lines...\n",
      "Processed 176900000 lines...\n",
      "Processed 177000000 lines...\n",
      "Processed 177100000 lines...\n",
      "Processed 177200000 lines...\n",
      "Processed 177300000 lines...\n",
      "Processed 177400000 lines...\n",
      "Processed 177500000 lines...\n",
      "Processed 177600000 lines...\n",
      "Processed 177700000 lines...\n",
      "Processed 177800000 lines...\n",
      "Processed 177900000 lines...\n",
      "Processed 178000000 lines...\n",
      "Processed 178100000 lines...\n",
      "Processed 178200000 lines...\n",
      "Processed 178300000 lines...\n",
      "Processed 178400000 lines...\n",
      "Processed 178500000 lines...\n",
      "Processed 178600000 lines...\n",
      "Processed 178700000 lines...\n",
      "Processed 178800000 lines...\n",
      "Processed 178900000 lines...\n",
      "Processed 179000000 lines...\n",
      "Processed 179100000 lines...\n",
      "Processed 179200000 lines...\n",
      "Processed 179300000 lines...\n",
      "Processed 179400000 lines...\n",
      "Processed 179500000 lines...\n",
      "Processed 179600000 lines...\n",
      "Processed 179700000 lines...\n",
      "Processed 179800000 lines...\n",
      "Processed 179900000 lines...\n",
      "Processed 180000000 lines...\n",
      "Processed 180100000 lines...\n",
      "Processed 180200000 lines...\n",
      "Processed 180300000 lines...\n",
      "Processed 180400000 lines...\n",
      "Processed 180500000 lines...\n",
      "Processed 180600000 lines...\n",
      "Processed 180700000 lines...\n",
      "Processed 180800000 lines...\n",
      "Processed 180900000 lines...\n",
      "Processed 181000000 lines...\n",
      "Processed 181100000 lines...\n",
      "Processed 181200000 lines...\n",
      "Processed 181300000 lines...\n",
      "Processed 181400000 lines...\n",
      "Processed 181500000 lines...\n",
      "Processed 181600000 lines...\n",
      "Processed 181700000 lines...\n",
      "Processed 181800000 lines...\n",
      "Processed 181900000 lines...\n",
      "Processed 182000000 lines...\n",
      "Processed 182100000 lines...\n",
      "Processed 182200000 lines...\n",
      "Processed 182300000 lines...\n",
      "Processed 182400000 lines...\n",
      "Processed 182500000 lines...\n",
      "Processed 182600000 lines...\n",
      "Processed 182700000 lines...\n",
      "Processed 182800000 lines...\n",
      "Processed 182900000 lines...\n",
      "Processed 183000000 lines...\n",
      "Processed 183100000 lines...\n",
      "Processed 183200000 lines...\n",
      "Processed 183300000 lines...\n",
      "Processed 183400000 lines...\n",
      "Processed 183500000 lines...\n",
      "Processed 183600000 lines...\n",
      "Processed 183700000 lines...\n",
      "Processed 183800000 lines...\n",
      "Processed 183900000 lines...\n",
      "Processed 184000000 lines...\n",
      "Processed 184100000 lines...\n",
      "Processed 184200000 lines...\n",
      "Processed 184300000 lines...\n",
      "Processed 184400000 lines...\n",
      "Processed 184500000 lines...\n",
      "Processed 184600000 lines...\n",
      "Processed 184700000 lines...\n",
      "Processed 184800000 lines...\n",
      "Processed 184900000 lines...\n",
      "Processed 185000000 lines...\n",
      "Processed 185100000 lines...\n",
      "Processed 185200000 lines...\n",
      "Processed 185300000 lines...\n",
      "Processed 185400000 lines...\n",
      "Processed 185500000 lines...\n",
      "Processed 185600000 lines...\n",
      "Processed 185700000 lines...\n",
      "Processed 185800000 lines...\n",
      "Processed 185900000 lines...\n",
      "Processed 186000000 lines...\n",
      "Processed 186100000 lines...\n",
      "Processed 186200000 lines...\n",
      "Processed 186300000 lines...\n",
      "Processed 186400000 lines...\n",
      "Processed 186500000 lines...\n",
      "Processed 186600000 lines...\n",
      "Processed 186700000 lines...\n",
      "Processed 186800000 lines...\n",
      "Processed 186900000 lines...\n",
      "Processed 187000000 lines...\n",
      "Processed 187100000 lines...\n",
      "Processed 187200000 lines...\n",
      "Processed 187300000 lines...\n",
      "Processed 187400000 lines...\n",
      "Processed 187500000 lines...\n",
      "Processed 187600000 lines...\n",
      "Processed 187700000 lines...\n",
      "Processed 187800000 lines...\n",
      "Processed 187900000 lines...\n",
      "Processed 188000000 lines...\n",
      "Processed 188100000 lines...\n",
      "Processed 188200000 lines...\n",
      "Processed 188300000 lines...\n",
      "Processed 188400000 lines...\n",
      "Processed 188500000 lines...\n",
      "Processed 188600000 lines...\n",
      "Processed 188700000 lines...\n",
      "Processed 188800000 lines...\n",
      "Processed 188900000 lines...\n",
      "Processed 189000000 lines...\n",
      "Processed 189100000 lines...\n",
      "Processed 189200000 lines...\n",
      "Processed 189300000 lines...\n",
      "Processed 189400000 lines...\n",
      "Processed 189500000 lines...\n",
      "Processed 189600000 lines...\n",
      "Processed 189700000 lines...\n",
      "Processed 189800000 lines...\n",
      "Processed 189900000 lines...\n",
      "Processed 190000000 lines...\n",
      "Processed 190100000 lines...\n",
      "Processed 190200000 lines...\n",
      "Processed 190300000 lines...\n",
      "Processed 190400000 lines...\n",
      "Processed 190500000 lines...\n",
      "Processed 190600000 lines...\n",
      "Processed 190700000 lines...\n",
      "Processed 190800000 lines...\n",
      "Processed 190900000 lines...\n",
      "Processed 191000000 lines...\n",
      "Processed 191100000 lines...\n",
      "Processed 191200000 lines...\n",
      "Processed 191300000 lines...\n",
      "Processed 191400000 lines...\n",
      "Processed 191500000 lines...\n",
      "Processed 191600000 lines...\n",
      "Processed 191700000 lines...\n",
      "Processed 191800000 lines...\n",
      "Processed 191900000 lines...\n",
      "Processed 192000000 lines...\n",
      "Processed 192100000 lines...\n",
      "Processed 192200000 lines...\n",
      "Processed 192300000 lines...\n",
      "Processed 192400000 lines...\n",
      "Processed 192500000 lines...\n",
      "Processed 192600000 lines...\n",
      "Processed 192700000 lines...\n",
      "Processed 192800000 lines...\n",
      "Processed 192900000 lines...\n",
      "Processed 193000000 lines...\n",
      "Processed 193100000 lines...\n",
      "Processed 193200000 lines...\n",
      "Processed 193300000 lines...\n",
      "Processed 193400000 lines...\n",
      "Processed 193500000 lines...\n",
      "Processed 193600000 lines...\n",
      "Processed 193700000 lines...\n",
      "Processed 193800000 lines...\n",
      "Processed 193900000 lines...\n",
      "Processed 194000000 lines...\n",
      "Processed 194100000 lines...\n",
      "Processed 194200000 lines...\n",
      "Processed 194300000 lines...\n",
      "Processed 194400000 lines...\n",
      "Processed 194500000 lines...\n",
      "Processed 194600000 lines...\n",
      "Processed 194700000 lines...\n",
      "Processed 194800000 lines...\n",
      "Processed 194900000 lines...\n",
      "Processed 195000000 lines...\n",
      "Processed 195100000 lines...\n",
      "Processed 195200000 lines...\n",
      "Processed 195300000 lines...\n",
      "Processed 195400000 lines...\n",
      "Processed 195500000 lines...\n",
      "Processed 195600000 lines...\n",
      "Processed 195700000 lines...\n",
      "Processed 195800000 lines...\n",
      "Processed 195900000 lines...\n",
      "Processed 196000000 lines...\n",
      "Processed 196100000 lines...\n",
      "Processed 196200000 lines...\n",
      "Processed 196300000 lines...\n",
      "Processed 196400000 lines...\n",
      "Processed 196500000 lines...\n",
      "Processed 196600000 lines...\n",
      "Processed 196700000 lines...\n",
      "Processed 196800000 lines...\n",
      "Processed 196900000 lines...\n",
      "Processed 197000000 lines...\n",
      "Processed 197100000 lines...\n",
      "Processed 197200000 lines...\n",
      "Processed 197300000 lines...\n",
      "Processed 197400000 lines...\n",
      "Processed 197500000 lines...\n",
      "Processed 197600000 lines...\n",
      "Processed 197700000 lines...\n",
      "Processed 197800000 lines...\n",
      "Processed 197900000 lines...\n",
      "Processed 198000000 lines...\n",
      "Processed 198100000 lines...\n",
      "Processed 198200000 lines...\n",
      "Processed 198300000 lines...\n",
      "Processed 198400000 lines...\n",
      "Processed 198500000 lines...\n",
      "Processed 198600000 lines...\n",
      "Processed 198700000 lines...\n",
      "Processed 198800000 lines...\n",
      "Processed 198900000 lines...\n",
      "Processed 199000000 lines...\n",
      "Processed 199100000 lines...\n",
      "Processed 199200000 lines...\n",
      "Processed 199300000 lines...\n",
      "Processed 199400000 lines...\n",
      "Processed 199500000 lines...\n",
      "Processed 199600000 lines...\n",
      "Processed 199700000 lines...\n",
      "Processed 199800000 lines...\n",
      "Processed 199900000 lines...\n",
      "Processed 200000000 lines...\n",
      "Processed 200100000 lines...\n",
      "Processed 200200000 lines...\n",
      "Processed 200300000 lines...\n",
      "Processed 200400000 lines...\n",
      "Processed 200500000 lines...\n",
      "Processed 200600000 lines...\n",
      "Processed 200700000 lines...\n",
      "Processed 200800000 lines...\n",
      "Processed 200900000 lines...\n",
      "Processed 201000000 lines...\n",
      "Processed 201100000 lines...\n",
      "Processed 201200000 lines...\n",
      "Processed 201300000 lines...\n",
      "Processed 201400000 lines...\n",
      "Processed 201500000 lines...\n",
      "Processed 201600000 lines...\n",
      "Processed 201700000 lines...\n",
      "Processed 201800000 lines...\n",
      "Processed 201900000 lines...\n",
      "Processed 202000000 lines...\n",
      "Processed 202100000 lines...\n",
      "Processed 202200000 lines...\n",
      "Processed 202300000 lines...\n",
      "Processed 202400000 lines...\n",
      "Processed 202500000 lines...\n",
      "Processed 202600000 lines...\n",
      "Processed 202700000 lines...\n",
      "Processed 202800000 lines...\n",
      "Processed 202900000 lines...\n",
      "Processed 203000000 lines...\n",
      "Processed 203100000 lines...\n",
      "Processed 203200000 lines...\n",
      "Processed 203300000 lines...\n",
      "Processed 203400000 lines...\n",
      "Processed 203500000 lines...\n",
      "Processed 203600000 lines...\n",
      "Processed 203700000 lines...\n",
      "Processed 203800000 lines...\n",
      "Processed 203900000 lines...\n",
      "Processed 204000000 lines...\n",
      "Processed 204100000 lines...\n",
      "Processed 204200000 lines...\n",
      "Processed 204300000 lines...\n",
      "Processed 204400000 lines...\n",
      "Processed 204500000 lines...\n",
      "Processed 204600000 lines...\n",
      "Processed 204700000 lines...\n",
      "Processed 204800000 lines...\n",
      "Processed 204900000 lines...\n",
      "Processed 205000000 lines...\n",
      "Processed 205100000 lines...\n",
      "Processed 205200000 lines...\n",
      "Processed 205300000 lines...\n",
      "Processed 205400000 lines...\n",
      "Processed 205500000 lines...\n",
      "Processed 205600000 lines...\n",
      "Processed 205700000 lines...\n",
      "Processed 205800000 lines...\n",
      "Processed 205900000 lines...\n",
      "Processed 206000000 lines...\n",
      "Processed 206100000 lines...\n",
      "Processed 206200000 lines...\n",
      "Processed 206300000 lines...\n",
      "Processed 206400000 lines...\n",
      "Processed 206500000 lines...\n",
      "Processed 206600000 lines...\n",
      "Processed 206700000 lines...\n",
      "Processed 206800000 lines...\n",
      "Processed 206900000 lines...\n",
      "Processed 207000000 lines...\n",
      "Processed 207100000 lines...\n",
      "Processed 207200000 lines...\n",
      "Processed 207300000 lines...\n",
      "Processed 207400000 lines...\n",
      "Processed 207500000 lines...\n",
      "Processed 207600000 lines...\n",
      "Processed 207700000 lines...\n",
      "Processed 207800000 lines...\n",
      "Processed 207900000 lines...\n",
      "Processed 208000000 lines...\n",
      "Processed 208100000 lines...\n",
      "Processed 208200000 lines...\n",
      "Processed 208300000 lines...\n",
      "Processed 208400000 lines...\n",
      "Processed 208500000 lines...\n",
      "Processed 208600000 lines...\n",
      "Processed 208700000 lines...\n",
      "Processed 208800000 lines...\n",
      "Processed 208900000 lines...\n",
      "Processed 209000000 lines...\n",
      "Processed 209100000 lines...\n",
      "Processed 209200000 lines...\n",
      "Processed 209300000 lines...\n",
      "Processed 209400000 lines...\n",
      "Processed 209500000 lines...\n",
      "Processed 209600000 lines...\n",
      "Processed 209700000 lines...\n",
      "Processed 209800000 lines...\n",
      "Processed 209900000 lines...\n",
      "Processed 210000000 lines...\n",
      "Processed 210100000 lines...\n",
      "Processed 210200000 lines...\n",
      "Processed 210300000 lines...\n",
      "Processed 210400000 lines...\n",
      "Processed 210500000 lines...\n",
      "Processed 210600000 lines...\n",
      "Processed 210700000 lines...\n",
      "Processed 210800000 lines...\n",
      "Processed 210900000 lines...\n",
      "Processed 211000000 lines...\n",
      "Processed 211100000 lines...\n",
      "Processed 211200000 lines...\n",
      "Processed 211300000 lines...\n",
      "Processed 211400000 lines...\n",
      "Processed 211500000 lines...\n",
      "Processed 211600000 lines...\n",
      "Processed 211700000 lines...\n",
      "Processed 211800000 lines...\n",
      "Processed 211900000 lines...\n",
      "Processed 212000000 lines...\n",
      "Processed 212100000 lines...\n",
      "Processed 212200000 lines...\n",
      "Processed 212300000 lines...\n",
      "Processed 212400000 lines...\n",
      "Processed 212500000 lines...\n",
      "Processed 212600000 lines...\n",
      "Processed 212700000 lines...\n",
      "Processed 212800000 lines...\n",
      "Processed 212900000 lines...\n",
      "Processed 213000000 lines...\n",
      "Processed 213100000 lines...\n",
      "Processed 213200000 lines...\n",
      "Processed 213300000 lines...\n",
      "Processed 213400000 lines...\n",
      "Processed 213500000 lines...\n",
      "Processed 213600000 lines...\n",
      "Processed 213700000 lines...\n",
      "Processed 213800000 lines...\n",
      "Processed 213900000 lines...\n",
      "Processed 214000000 lines...\n",
      "Processed 214100000 lines...\n",
      "Processed 214200000 lines...\n",
      "Processed 214300000 lines...\n",
      "Processed 214400000 lines...\n",
      "Processed 214500000 lines...\n",
      "Processed 214600000 lines...\n",
      "Processed 214700000 lines...\n",
      "Processed 214800000 lines...\n",
      "Processed 214900000 lines...\n",
      "Processed 215000000 lines...\n",
      "Processed 215100000 lines...\n",
      "Processed 215200000 lines...\n",
      "Processed 215300000 lines...\n",
      "Processed 215400000 lines...\n",
      "Processed 215500000 lines...\n",
      "Processed 215600000 lines...\n",
      "Processed 215700000 lines...\n",
      "Processed 215800000 lines...\n",
      "Processed 215900000 lines...\n",
      "Processed 216000000 lines...\n",
      "Processed 216100000 lines...\n",
      "Processed 216200000 lines...\n",
      "Pre-processing completed.\n",
      "Starting to process the temporary CSV in chunks...\n",
      "Processing chunk 1...\n",
      "Processing chunk 2...\n",
      "Processing chunk 3...\n",
      "Processing chunk 4...\n",
      "Processing chunk 5...\n",
      "Processing chunk 6...\n",
      "Processing chunk 7...\n",
      "Processing chunk 8...\n",
      "Processing chunk 9...\n",
      "Processing chunk 10...\n",
      "Processing chunk 11...\n",
      "Processing chunk 12...\n",
      "Processing chunk 13...\n",
      "Processing chunk 14...\n",
      "Processing chunk 15...\n",
      "Processing chunk 16...\n",
      "Processing chunk 17...\n",
      "Processing chunk 18...\n",
      "Processing chunk 19...\n",
      "Processing chunk 20...\n",
      "Processing chunk 21...\n",
      "Processing chunk 22...\n",
      "Processing chunk 23...\n",
      "Processing chunk 24...\n",
      "Processing chunk 25...\n",
      "Processing chunk 26...\n",
      "Processing chunk 27...\n",
      "Processing chunk 28...\n",
      "Processing chunk 29...\n",
      "Processing chunk 30...\n",
      "Processing chunk 31...\n",
      "Processing chunk 32...\n",
      "Processing chunk 33...\n",
      "Processing chunk 34...\n",
      "Processing chunk 35...\n",
      "Processing chunk 36...\n",
      "Processing chunk 37...\n",
      "Processing chunk 38...\n",
      "Processing chunk 39...\n",
      "Processing chunk 40...\n",
      "Processing chunk 41...\n",
      "Processing chunk 42...\n",
      "Processing chunk 43...\n",
      "Processing chunk 44...\n",
      "Processing chunk 45...\n",
      "Processing chunk 46...\n",
      "Processing chunk 47...\n",
      "Processing chunk 48...\n",
      "Processing chunk 49...\n",
      "Processing chunk 50...\n",
      "Processing chunk 51...\n",
      "Processing chunk 52...\n",
      "Processing chunk 53...\n",
      "Processing chunk 54...\n",
      "Processing chunk 55...\n",
      "Processing chunk 56...\n",
      "Processing chunk 57...\n",
      "Processing chunk 58...\n",
      "Processing chunk 59...\n",
      "Processing chunk 60...\n",
      "Processing chunk 61...\n",
      "Processing chunk 62...\n",
      "Processing chunk 63...\n",
      "Processing chunk 64...\n",
      "Processing chunk 65...\n",
      "Processing chunk 66...\n",
      "Processing chunk 67...\n",
      "Processing chunk 68...\n",
      "Processing chunk 69...\n",
      "Processing chunk 70...\n",
      "Processing chunk 71...\n",
      "Processing chunk 72...\n",
      "Processing chunk 73...\n",
      "Processing chunk 74...\n",
      "Processing chunk 75...\n",
      "Processing chunk 76...\n",
      "Processing chunk 77...\n",
      "Processing chunk 78...\n",
      "Processing chunk 79...\n",
      "Processing chunk 80...\n",
      "Processing chunk 81...\n",
      "Processing chunk 82...\n",
      "Processing chunk 83...\n",
      "Processing chunk 84...\n",
      "Processing chunk 85...\n",
      "Processing chunk 86...\n",
      "Processing chunk 87...\n",
      "Processing chunk 88...\n",
      "Processing chunk 89...\n",
      "Processing chunk 90...\n",
      "Processing chunk 91...\n",
      "Processing chunk 92...\n",
      "Processing chunk 93...\n",
      "Processing chunk 94...\n",
      "Processing chunk 95...\n",
      "Processing chunk 96...\n",
      "Processing chunk 97...\n",
      "Processing chunk 98...\n",
      "Processing chunk 99...\n",
      "Processing chunk 100...\n",
      "Processing chunk 101...\n",
      "Processing chunk 102...\n",
      "Processing chunk 103...\n",
      "Processing chunk 104...\n",
      "Processing chunk 105...\n",
      "Processing chunk 106...\n",
      "Processing chunk 107...\n",
      "Processing chunk 108...\n",
      "Processing chunk 109...\n",
      "Processing chunk 110...\n",
      "Processing chunk 111...\n",
      "Processing chunk 112...\n",
      "Processing chunk 113...\n",
      "Processing chunk 114...\n",
      "Processing chunk 115...\n",
      "Processing chunk 116...\n",
      "Processing chunk 117...\n",
      "Processing chunk 118...\n",
      "Processing chunk 119...\n",
      "Processing chunk 120...\n",
      "Processing chunk 121...\n",
      "Processing chunk 122...\n",
      "Processing chunk 123...\n",
      "Processing chunk 124...\n",
      "Processing chunk 125...\n",
      "Processing chunk 126...\n",
      "Processing chunk 127...\n",
      "Processing chunk 128...\n",
      "Processing chunk 129...\n",
      "Processing chunk 130...\n",
      "Processing chunk 131...\n",
      "Processing chunk 132...\n",
      "Processing chunk 133...\n",
      "Processing chunk 134...\n",
      "Processing chunk 135...\n",
      "Processing chunk 136...\n",
      "Processing chunk 137...\n",
      "Processing chunk 138...\n",
      "Processing chunk 139...\n",
      "Processing chunk 140...\n",
      "Processing chunk 141...\n",
      "Processing chunk 142...\n",
      "Processing chunk 143...\n",
      "Processing chunk 144...\n",
      "Processing chunk 145...\n",
      "Processing chunk 146...\n",
      "Processing chunk 147...\n",
      "Processing chunk 148...\n",
      "Processing chunk 149...\n",
      "Processing chunk 150...\n",
      "Processing chunk 151...\n",
      "Processing chunk 152...\n",
      "Processing chunk 153...\n",
      "Processing chunk 154...\n",
      "Processing chunk 155...\n",
      "Processing chunk 156...\n",
      "Processing chunk 157...\n",
      "Processing chunk 158...\n",
      "Processing chunk 159...\n",
      "Processing chunk 160...\n",
      "Processing chunk 161...\n",
      "Processing chunk 162...\n",
      "Processing chunk 163...\n",
      "Processing chunk 164...\n",
      "Processing chunk 165...\n",
      "Processing chunk 166...\n",
      "Processing chunk 167...\n",
      "Processing chunk 168...\n",
      "Processing chunk 169...\n",
      "Processing chunk 170...\n",
      "Processing chunk 171...\n",
      "Processing chunk 172...\n",
      "Processing chunk 173...\n",
      "Processing chunk 174...\n",
      "Processing chunk 175...\n",
      "Processing chunk 176...\n",
      "Processing chunk 177...\n",
      "Processing chunk 178...\n",
      "Processing chunk 179...\n",
      "Processing chunk 180...\n",
      "Processing chunk 181...\n",
      "Processing chunk 182...\n",
      "Processing chunk 183...\n",
      "Processing chunk 184...\n",
      "Processing chunk 185...\n",
      "Processing chunk 186...\n",
      "Processing chunk 187...\n",
      "Processing chunk 188...\n",
      "Processing chunk 189...\n",
      "Processing chunk 190...\n",
      "Processing chunk 191...\n",
      "Processing chunk 192...\n",
      "Processing chunk 193...\n",
      "Processing chunk 194...\n",
      "Processing chunk 195...\n",
      "Processing chunk 196...\n",
      "Processing chunk 197...\n",
      "Processing chunk 198...\n",
      "Processing chunk 199...\n",
      "Processing chunk 200...\n",
      "Processing chunk 201...\n",
      "Processing chunk 202...\n",
      "Processing chunk 203...\n",
      "Processing chunk 204...\n",
      "Processing chunk 205...\n",
      "Processing chunk 206...\n",
      "Processing chunk 207...\n",
      "Processing chunk 208...\n",
      "Processing chunk 209...\n",
      "Processing chunk 210...\n",
      "Processing chunk 211...\n",
      "Processing chunk 212...\n",
      "Processing chunk 213...\n",
      "Processing chunk 214...\n",
      "Processing chunk 215...\n",
      "Processing chunk 216...\n",
      "Processing chunk 217...\n",
      "Processing chunk 218...\n",
      "Processing chunk 219...\n",
      "Processing chunk 220...\n",
      "Processing chunk 221...\n",
      "Processing chunk 222...\n",
      "Processing chunk 223...\n",
      "Processing chunk 224...\n",
      "Processing chunk 225...\n",
      "Processing chunk 226...\n",
      "Processing chunk 227...\n",
      "Processing chunk 228...\n",
      "Processing chunk 229...\n",
      "Processing chunk 230...\n",
      "Processing chunk 231...\n",
      "Processing chunk 232...\n",
      "Processing chunk 233...\n",
      "Processing chunk 234...\n",
      "Processing chunk 235...\n",
      "Processing chunk 236...\n",
      "Processing chunk 237...\n",
      "Processing chunk 238...\n",
      "Processing chunk 239...\n",
      "Processing chunk 240...\n",
      "Processing chunk 241...\n",
      "Processing chunk 242...\n",
      "Processing chunk 243...\n",
      "Processing chunk 244...\n",
      "Processing chunk 245...\n",
      "Processing chunk 246...\n",
      "Processing chunk 247...\n",
      "Processing chunk 248...\n",
      "Processing chunk 249...\n",
      "Processing chunk 250...\n",
      "Processing chunk 251...\n",
      "Processing chunk 252...\n",
      "Processing chunk 253...\n",
      "Processing chunk 254...\n",
      "Processing chunk 255...\n",
      "Processing chunk 256...\n",
      "Processing chunk 257...\n",
      "Processing chunk 258...\n",
      "Processing chunk 259...\n",
      "Processing chunk 260...\n",
      "Processing chunk 261...\n",
      "Processing chunk 262...\n",
      "Processing chunk 263...\n",
      "Processing chunk 264...\n",
      "Processing chunk 265...\n",
      "Processing chunk 266...\n",
      "Processing chunk 267...\n",
      "Processing chunk 268...\n",
      "Processing chunk 269...\n",
      "Processing chunk 270...\n",
      "Processing chunk 271...\n",
      "Processing chunk 272...\n",
      "Processing chunk 273...\n",
      "Processing chunk 274...\n",
      "Processing chunk 275...\n",
      "Processing chunk 276...\n",
      "Processing chunk 277...\n",
      "Processing chunk 278...\n",
      "Processing chunk 279...\n",
      "Processing chunk 280...\n",
      "Processing chunk 281...\n",
      "Processing chunk 282...\n",
      "Processing chunk 283...\n",
      "Processing chunk 284...\n",
      "Processing chunk 285...\n",
      "Processing chunk 286...\n",
      "Processing chunk 287...\n",
      "Processing chunk 288...\n",
      "Processing chunk 289...\n",
      "Processing chunk 290...\n",
      "Processing chunk 291...\n",
      "Processing chunk 292...\n",
      "Processing chunk 293...\n",
      "Processing chunk 294...\n",
      "Processing chunk 295...\n",
      "Processing chunk 296...\n",
      "Processing chunk 297...\n",
      "Processing chunk 298...\n",
      "Processing chunk 299...\n",
      "Processing chunk 300...\n",
      "Processing chunk 301...\n",
      "Processing chunk 302...\n",
      "Processing chunk 303...\n",
      "Processing chunk 304...\n",
      "Processing chunk 305...\n",
      "Processing chunk 306...\n",
      "Processing chunk 307...\n",
      "Processing chunk 308...\n",
      "Processing chunk 309...\n",
      "Processing chunk 310...\n",
      "Processing chunk 311...\n",
      "Processing chunk 312...\n",
      "Processing chunk 313...\n",
      "Processing chunk 314...\n",
      "Processing chunk 315...\n",
      "Processing chunk 316...\n",
      "Processing chunk 317...\n",
      "Processing chunk 318...\n",
      "Processing chunk 319...\n",
      "Processing chunk 320...\n",
      "Processing chunk 321...\n",
      "Processing chunk 322...\n",
      "Processing chunk 323...\n",
      "Processing chunk 324...\n",
      "Processing chunk 325...\n",
      "Processing chunk 326...\n",
      "Processing chunk 327...\n",
      "Processing chunk 328...\n",
      "Processing chunk 329...\n",
      "Processing chunk 330...\n",
      "Processing chunk 331...\n",
      "Processing chunk 332...\n",
      "Processing chunk 333...\n",
      "Processing chunk 334...\n",
      "Processing chunk 335...\n",
      "Processing chunk 336...\n",
      "Processing chunk 337...\n",
      "Processing chunk 338...\n",
      "Processing chunk 339...\n",
      "Processing chunk 340...\n",
      "Processing chunk 341...\n",
      "Processing chunk 342...\n",
      "Processing chunk 343...\n",
      "Processing chunk 344...\n",
      "Processing chunk 345...\n",
      "Processing chunk 346...\n",
      "Processing chunk 347...\n",
      "Processing chunk 348...\n",
      "Processing chunk 349...\n",
      "Processing chunk 350...\n",
      "Processing chunk 351...\n",
      "Processing chunk 352...\n",
      "Processing chunk 353...\n",
      "Processing chunk 354...\n",
      "Processing chunk 355...\n",
      "Processing chunk 356...\n",
      "Processing chunk 357...\n",
      "Processing chunk 358...\n",
      "Processing chunk 359...\n",
      "Processing chunk 360...\n",
      "Processing chunk 361...\n",
      "Processing chunk 362...\n",
      "Processing chunk 363...\n",
      "Processing chunk 364...\n",
      "Processing chunk 365...\n",
      "Processing chunk 366...\n",
      "Processing chunk 367...\n",
      "Processing chunk 368...\n",
      "Processing chunk 369...\n",
      "Processing chunk 370...\n",
      "Processing chunk 371...\n",
      "Processing chunk 372...\n",
      "Processing chunk 373...\n",
      "Processing chunk 374...\n",
      "Processing chunk 375...\n",
      "Processing chunk 376...\n",
      "Processing chunk 377...\n",
      "Processing chunk 378...\n",
      "Processing chunk 379...\n",
      "Processing chunk 380...\n",
      "Processing chunk 381...\n",
      "Processing chunk 382...\n",
      "Processing chunk 383...\n",
      "Processing chunk 384...\n",
      "Processing chunk 385...\n",
      "Processing chunk 386...\n",
      "Processing chunk 387...\n",
      "Processing chunk 388...\n",
      "Processing chunk 389...\n",
      "Processing chunk 390...\n",
      "Processing chunk 391...\n",
      "Processing chunk 392...\n",
      "Processing chunk 393...\n",
      "Processing chunk 394...\n",
      "Processing chunk 395...\n",
      "Processing chunk 396...\n",
      "Processing chunk 397...\n",
      "Processing chunk 398...\n",
      "Processing chunk 399...\n",
      "Processing chunk 400...\n",
      "Processing chunk 401...\n",
      "Processing chunk 402...\n",
      "Processing chunk 403...\n",
      "Processing chunk 404...\n",
      "Processing chunk 405...\n",
      "Processing chunk 406...\n",
      "Processing chunk 407...\n",
      "Processing chunk 408...\n",
      "Processing chunk 409...\n",
      "Processing chunk 410...\n",
      "Processing chunk 411...\n",
      "Processing chunk 412...\n",
      "Processing chunk 413...\n",
      "Processing chunk 414...\n",
      "Processing chunk 415...\n",
      "Processing chunk 416...\n",
      "Processing chunk 417...\n",
      "Processing chunk 418...\n",
      "Processing chunk 419...\n",
      "Processing chunk 420...\n",
      "Processing chunk 421...\n",
      "Processing chunk 422...\n",
      "Processing chunk 423...\n",
      "Processing chunk 424...\n",
      "Processing chunk 425...\n",
      "Processing chunk 426...\n",
      "Processing chunk 427...\n",
      "Processing chunk 428...\n",
      "Processing chunk 429...\n",
      "Processing chunk 430...\n",
      "Processing chunk 431...\n",
      "Processing chunk 432...\n",
      "Processing chunk 433...\n",
      "Processing chunk 434...\n",
      "Processing chunk 435...\n",
      "Processing chunk 436...\n",
      "Processing chunk 437...\n",
      "Processing chunk 438...\n",
      "Processing chunk 439...\n",
      "Processing chunk 440...\n",
      "Processing chunk 441...\n",
      "Processing chunk 442...\n",
      "Processing chunk 443...\n",
      "Processing chunk 444...\n",
      "Processing chunk 445...\n",
      "Processing chunk 446...\n",
      "Processing chunk 447...\n",
      "Processing chunk 448...\n",
      "Processing chunk 449...\n",
      "Processing chunk 450...\n",
      "Processing chunk 451...\n",
      "Processing chunk 452...\n",
      "Processing chunk 453...\n",
      "Processing chunk 454...\n",
      "Processing chunk 455...\n",
      "Processing chunk 456...\n",
      "Processing chunk 457...\n",
      "Processing chunk 458...\n",
      "Processing chunk 459...\n",
      "Processing chunk 460...\n",
      "Processing chunk 461...\n",
      "Processing chunk 462...\n",
      "Processing chunk 463...\n",
      "Processing chunk 464...\n",
      "Processing chunk 465...\n",
      "Processing chunk 466...\n",
      "Processing chunk 467...\n",
      "Processing chunk 468...\n",
      "Processing chunk 469...\n",
      "Processing chunk 470...\n",
      "Processing chunk 471...\n",
      "Processing chunk 472...\n",
      "Processing chunk 473...\n",
      "Processing chunk 474...\n",
      "Processing chunk 475...\n",
      "Processing chunk 476...\n",
      "Processing chunk 477...\n",
      "Processing chunk 478...\n",
      "Processing chunk 479...\n",
      "Processing chunk 480...\n",
      "Processing chunk 481...\n",
      "Processing chunk 482...\n",
      "Processing chunk 483...\n",
      "Processing chunk 484...\n",
      "Processing chunk 485...\n",
      "Processing chunk 486...\n",
      "Processing chunk 487...\n",
      "Processing chunk 488...\n",
      "Processing chunk 489...\n",
      "Processing chunk 490...\n",
      "Processing chunk 491...\n",
      "Processing chunk 492...\n",
      "Processing chunk 493...\n",
      "Processing chunk 494...\n",
      "Processing chunk 495...\n",
      "Processing chunk 496...\n",
      "Processing chunk 497...\n",
      "Processing chunk 498...\n",
      "Processing chunk 499...\n",
      "Processing chunk 500...\n",
      "Processing chunk 501...\n",
      "Processing chunk 502...\n",
      "Processing chunk 503...\n",
      "Processing chunk 504...\n",
      "Processing chunk 505...\n",
      "Processing chunk 506...\n",
      "Processing chunk 507...\n",
      "Processing chunk 508...\n",
      "Processing chunk 509...\n",
      "Processing chunk 510...\n",
      "Processing chunk 511...\n",
      "Processing chunk 512...\n",
      "Processing chunk 513...\n",
      "Processing chunk 514...\n",
      "Processing chunk 515...\n",
      "Processing chunk 516...\n",
      "Processing chunk 517...\n",
      "Processing chunk 518...\n",
      "Processing chunk 519...\n",
      "Processing chunk 520...\n",
      "Processing chunk 521...\n",
      "Processing chunk 522...\n",
      "Processing chunk 523...\n",
      "Processing chunk 524...\n",
      "Processing chunk 525...\n",
      "Processing chunk 526...\n",
      "Processing chunk 527...\n",
      "Processing chunk 528...\n",
      "Processing chunk 529...\n",
      "Processing chunk 530...\n",
      "Processing chunk 531...\n",
      "Processing chunk 532...\n",
      "Processing chunk 533...\n",
      "Processing chunk 534...\n",
      "Processing chunk 535...\n",
      "Processing chunk 536...\n",
      "Processing chunk 537...\n",
      "Processing chunk 538...\n",
      "Processing chunk 539...\n",
      "Processing chunk 540...\n",
      "Processing chunk 541...\n",
      "Processing chunk 542...\n",
      "Processing chunk 543...\n",
      "Processing chunk 544...\n",
      "Processing chunk 545...\n",
      "Processing chunk 546...\n",
      "Processing chunk 547...\n",
      "Processing chunk 548...\n",
      "Processing chunk 549...\n",
      "Processing chunk 550...\n",
      "Processing chunk 551...\n",
      "Processing chunk 552...\n",
      "Processing chunk 553...\n",
      "Processing chunk 554...\n",
      "Processing chunk 555...\n",
      "Processing chunk 556...\n",
      "Processing chunk 557...\n",
      "Processing chunk 558...\n",
      "Processing chunk 559...\n",
      "Processing chunk 560...\n",
      "Processing chunk 561...\n",
      "Processing chunk 562...\n",
      "Processing chunk 563...\n",
      "Processing chunk 564...\n",
      "Processing chunk 565...\n",
      "Processing chunk 566...\n",
      "Processing chunk 567...\n",
      "Processing chunk 568...\n",
      "Processing chunk 569...\n",
      "Processing chunk 570...\n",
      "Processing chunk 571...\n",
      "Processing chunk 572...\n",
      "Processing chunk 573...\n",
      "Processing chunk 574...\n",
      "Processing chunk 575...\n",
      "Processing chunk 576...\n",
      "Processing chunk 577...\n",
      "Processing chunk 578...\n",
      "Processing chunk 579...\n",
      "Processing chunk 580...\n",
      "Processing chunk 581...\n",
      "Processing chunk 582...\n",
      "Processing chunk 583...\n",
      "Processing chunk 584...\n",
      "Processing chunk 585...\n",
      "Processing chunk 586...\n",
      "Processing chunk 587...\n",
      "Processing chunk 588...\n",
      "Processing chunk 589...\n",
      "Processing chunk 590...\n",
      "Processing chunk 591...\n",
      "Processing chunk 592...\n",
      "Processing chunk 593...\n",
      "Processing chunk 594...\n",
      "Processing chunk 595...\n",
      "Processing chunk 596...\n",
      "Processing chunk 597...\n",
      "Processing chunk 598...\n",
      "Processing chunk 599...\n",
      "Processing chunk 600...\n",
      "Processing chunk 601...\n",
      "Processing chunk 602...\n",
      "Processing chunk 603...\n",
      "Processing chunk 604...\n",
      "Processing chunk 605...\n",
      "Processing chunk 606...\n",
      "Processing chunk 607...\n",
      "Processing chunk 608...\n",
      "Processing chunk 609...\n",
      "Processing chunk 610...\n",
      "Processing chunk 611...\n",
      "Processing chunk 612...\n",
      "Processing chunk 613...\n",
      "Processing chunk 614...\n",
      "Processing chunk 615...\n",
      "Processing chunk 616...\n",
      "Processing chunk 617...\n",
      "Processing chunk 618...\n",
      "Processing chunk 619...\n",
      "Processing chunk 620...\n",
      "Processing chunk 621...\n",
      "Processing chunk 622...\n",
      "Processing chunk 623...\n",
      "Processing chunk 624...\n",
      "Processing chunk 625...\n",
      "Processing chunk 626...\n",
      "Processing chunk 627...\n",
      "Processing chunk 628...\n",
      "Processing chunk 629...\n",
      "Processing chunk 630...\n",
      "Processing chunk 631...\n",
      "Processing chunk 632...\n",
      "Processing chunk 633...\n",
      "Processing chunk 634...\n",
      "Processing chunk 635...\n",
      "Processing chunk 636...\n",
      "Processing chunk 637...\n",
      "Processing chunk 638...\n",
      "Processing chunk 639...\n",
      "Processing chunk 640...\n",
      "Processing chunk 641...\n",
      "Processing chunk 642...\n",
      "Processing chunk 643...\n",
      "Processing chunk 644...\n",
      "Processing chunk 645...\n",
      "Processing chunk 646...\n",
      "Processing chunk 647...\n",
      "Processing chunk 648...\n",
      "Processing chunk 649...\n",
      "Processing chunk 650...\n",
      "Processing chunk 651...\n",
      "Processing chunk 652...\n",
      "Processing chunk 653...\n",
      "Processing chunk 654...\n",
      "Processing chunk 655...\n",
      "Processing chunk 656...\n",
      "Processing chunk 657...\n",
      "Processing chunk 658...\n",
      "Processing chunk 659...\n",
      "Processing chunk 660...\n",
      "Processing chunk 661...\n",
      "Processing chunk 662...\n",
      "Processing chunk 663...\n",
      "Processing chunk 664...\n",
      "Processing chunk 665...\n",
      "Processing chunk 666...\n",
      "Processing chunk 667...\n",
      "Collected enough samples.\n",
      "Processing completed.\n",
      "Concatenating samples...\n",
      "Combining and shuffling the dataset...\n",
      "Saving the processed dataset to /Users/ssadegh/Downloads/FakeNewsCorpus-master/processed_news.csv...\n",
      "Processing and saving completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# Increase the field size limit\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# Path to the original and temporary CSV files\n",
    "original_csv_path = '/Users/ssadegh/Downloads/FakeNewsCorpus-master/news_cleaned_2018_02_13.csv'\n",
    "temp_csv_path = '/Users/ssadegh/Downloads/FakeNewsCorpus-master/temp_news_cleaned.csv'\n",
    "\n",
    "# Pre-process the CSV to filter out bad lines\n",
    "print(\"Starting to pre-process the CSV to filter out bad lines...\")\n",
    "with open(original_csv_path, 'r', encoding='utf-8') as infile, open(temp_csv_path, 'w', encoding='utf-8') as outfile:\n",
    "    for i, line in enumerate(infile):\n",
    "        if i % 100000 == 0:\n",
    "            print(f\"Processed {i} lines...\")\n",
    "        try:\n",
    "            # Attempt to write the line to the new file\n",
    "            outfile.write(line)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping line {i} due to error: {e}\")\n",
    "\n",
    "print(\"Pre-processing completed.\")\n",
    "\n",
    "# Initialize parameters\n",
    "chunksize = 10000\n",
    "fake_count = 0\n",
    "reliable_count = 0\n",
    "max_rows = 50000  # since we need a 50-50 ratio, we limit each category to 50,000 rows\n",
    "fake_samples = []\n",
    "reliable_samples = []\n",
    "\n",
    "# Read and process the temporary CSV in chunks\n",
    "print(\"Starting to process the temporary CSV in chunks...\")\n",
    "with pd.read_csv(temp_csv_path, chunksize=chunksize, sep=',', engine='python') as reader:\n",
    "    for i, chunk in enumerate(reader):\n",
    "        print(f\"Processing chunk {i+1}...\")\n",
    "        # Filter relevant columns and rows\n",
    "        chunk = chunk[['title', 'content', 'type']]\n",
    "        chunk = chunk[chunk['type'].isin(['reliable', 'fake'])]\n",
    "\n",
    "        # Map labels\n",
    "        label_mapping = {'fake': 1, 'reliable': 0}\n",
    "        chunk['label'] = chunk['type'].map(label_mapping)\n",
    "\n",
    "        # Handle NaN values by filling them with empty strings and convert to string\n",
    "        chunk['title'] = chunk['title'].fillna('').astype(str)\n",
    "        chunk['content'] = chunk['content'].fillna('').astype(str)\n",
    "\n",
    "        # Combine title and content into a new column 'text'\n",
    "        chunk['text'] = chunk['title'] + \" \" + chunk['content']\n",
    "\n",
    "        # Separate fake and reliable articles\n",
    "        fake_chunk = chunk[chunk['label'] == 1]\n",
    "        reliable_chunk = chunk[chunk['label'] == 0]\n",
    "\n",
    "        # Add to samples if below max_rows\n",
    "        if fake_count < max_rows:\n",
    "            fake_samples.append(fake_chunk)\n",
    "            fake_count += len(fake_chunk)\n",
    "\n",
    "        if reliable_count < max_rows:\n",
    "            reliable_samples.append(reliable_chunk)\n",
    "            reliable_count += len(reliable_chunk)\n",
    "\n",
    "        # Stop if we have enough samples\n",
    "        if fake_count >= max_rows and reliable_count >= max_rows:\n",
    "            print(\"Collected enough samples.\")\n",
    "            break\n",
    "\n",
    "print(\"Processing completed.\")\n",
    "\n",
    "# Concatenate samples and limit to max_rows\n",
    "print(\"Concatenating samples...\")\n",
    "fake_samples = pd.concat(fake_samples)[:max_rows]\n",
    "reliable_samples = pd.concat(reliable_samples)[:max_rows]\n",
    "\n",
    "# Combine and shuffle the dataset\n",
    "print(\"Combining and shuffling the dataset...\")\n",
    "balanced_df = pd.concat([fake_samples, reliable_samples]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the processed dataset\n",
    "output_csv_path = '/Users/ssadegh/Downloads/FakeNewsCorpus-master/processed_news.csv'\n",
    "print(f\"Saving the processed dataset to {output_csv_path}...\")\n",
    "balanced_df.to_csv(output_csv_path, index=False, columns=['text', 'label', 'title'])\n",
    "\n",
    "print(\"Processing and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee03256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are the Culture Wars History?: A Conversation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Are the Culture Wars History?: A Conversation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blood Collection Chair Market Growth, Top Manu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood Collection Chair Market Growth, Top Manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrorist attack Archives ⋆ Dc Gazette Every n...</td>\n",
       "      <td>1</td>\n",
       "      <td>terrorist attack Archives ⋆ Dc Gazette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christian Life Coach to the Stars Tim Storey T...</td>\n",
       "      <td>0</td>\n",
       "      <td>Christian Life Coach to the Stars Tim Storey T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Israel’s Takeover of the Internet Israel’s Tak...</td>\n",
       "      <td>1</td>\n",
       "      <td>Israel’s Takeover of the Internet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Are the Culture Wars History?: A Conversation ...      1   \n",
       "1  Blood Collection Chair Market Growth, Top Manu...      1   \n",
       "2  terrorist attack Archives ⋆ Dc Gazette Every n...      1   \n",
       "3  Christian Life Coach to the Stars Tim Storey T...      0   \n",
       "4  Israel’s Takeover of the Internet Israel’s Tak...      1   \n",
       "\n",
       "                                               title  \n",
       "0  Are the Culture Wars History?: A Conversation ...  \n",
       "1  Blood Collection Chair Market Growth, Top Manu...  \n",
       "2             terrorist attack Archives ⋆ Dc Gazette  \n",
       "3  Christian Life Coach to the Stars Tim Storey T...  \n",
       "4                  Israel’s Takeover of the Internet  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/fnc_processed_news.csv')\n",
    "\n",
    "data_fnc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c43002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6663d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8282, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRows_fnc = data_fnc[data_fnc.duplicated()]\n",
    "duplicateRows_fnc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7bb947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91718, 3)\n"
     ]
    }
   ],
   "source": [
    "data_fnc_cleaned = data_fnc.drop_duplicates()\n",
    "print(data_fnc_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cef5aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                0\n",
       "label               0\n",
       "title               0\n",
       "all_text            0\n",
       "all_text_cleaned    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf326d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     False\n",
       "label    False\n",
       "title     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea0092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.537397\n",
       "0    0.462603\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da985165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"title\"] = data[\"title\"].fillna('').astype(str)\n",
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"text\"] = data[\"text\"].fillna('').astype(str)\n",
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"all_text\"] = data[\"title\"] + \" \" +  data[\"text\"]\n",
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"all_text_cleaned\"] = data[\"all_text\"].apply(preprocessing)\n"
     ]
    }
   ],
   "source": [
    "data_fnc_cleaned_preprocd = fnc_preprocessing(data_fnc_cleaned)\n",
    "# data_fnc_cleaned_preprocd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb34c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture war history conversation andrew hartma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood collection chair market growth top manuf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrorist attack archive ⋆ dc gazette terroris...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian life coach star tim storey talk past...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>israel takeover internet israel takeover inter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    all_text_cleaned  label\n",
       "0  culture war history conversation andrew hartma...      1\n",
       "1  blood collection chair market growth top manuf...      1\n",
       "2  terrorist attack archive ⋆ dc gazette terroris...      1\n",
       "3  christian life coach star tim storey talk past...      0\n",
       "4  israel takeover internet israel takeover inter...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned_preprocd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ffa28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91718, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned_preprocd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e987b46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                False\n",
       "label               False\n",
       "title               False\n",
       "all_text            False\n",
       "all_text_cleaned    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fnc_cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee5a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fnc_cleaned_preprocd.to_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/FNC_clean_preprocd.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112b7ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=43fe9a3e4b2ae7acfe01c585cfcd965502de64c922ac14318440b0c4b361f8f4\n",
      "  Stored in directory: /Users/ssadegh/Library/Caches/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fnc_cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "467b3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset integration\n",
    "\n",
    "data_integ_fnc = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/FNC_clean_preprocd.csv')\n",
    "data_integ_credcoal = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/CrediCoal_Fake.csv')\n",
    "data_integ_welf = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/WELFake_Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93b43146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"label\"] = data.label.replace(to_replace=['REAL', 'FAKE'], value=[0, 1])\n"
     ]
    }
   ],
   "source": [
    "data_integ_credcoal = join_text(data_integ_credcoal)\n",
    "data_integ_welf = join_text(data_integ_welf)\n",
    "\n",
    "\n",
    "data_integ_credcoal= cc_preprocessing(data_integ_credcoal)\n",
    "data_integ_welf = welf_preprocessing(data_integ_welf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3715f3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_text_cleaned    False\n",
       "label               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_integ_welf.isnull().any() #check no null !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4495dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unified_data = pd.concat([data_integ_fnc, data_integ_credcoal, data_integ_welf], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70f8e387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_text_cleaned    1\n",
       "label               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data.isnull().any()\n",
    "unified_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b848fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_text_cleaned    False\n",
       "label               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data = unified_data.dropna()\n",
    "unified_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6fe8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_data.to_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/unified_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6400e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170186, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69823936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/cm2b45810c14ksf_wpnjfcx40000gn/T/ipykernel_65772/3054907089.py:1: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_unified = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/unified_data.csv')\n"
     ]
    }
   ],
   "source": [
    "data_unified = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/unified_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09a2a12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170187, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fba71d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text_cleaned</th>\n",
       "      <th>label</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture war history conversation andrew hartma...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood collection chair market growth top manuf...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrorist attack archive ⋆ dc gazette terroris...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian life coach star tim storey talk past...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>israel takeover internet israel takeover inter...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    all_text_cleaned label  Unnamed: 0 title  \\\n",
       "0  culture war history conversation andrew hartma...     1         NaN   NaN   \n",
       "1  blood collection chair market growth top manuf...     1         NaN   NaN   \n",
       "2  terrorist attack archive ⋆ dc gazette terroris...     1         NaN   NaN   \n",
       "3  christian life coach star tim storey talk past...     0         NaN   NaN   \n",
       "4  israel takeover internet israel takeover inter...     1         NaN   NaN   \n",
       "\n",
       "  text  \n",
       "0  NaN  \n",
       "1  NaN  \n",
       "2  NaN  \n",
       "3  NaN  \n",
       "4  NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6a4009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_text_cleaned    756\n",
       "label                 0\n",
       "Unnamed: 0          946\n",
       "title               952\n",
       "text                947\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63dea5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait\n",
      "for\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test  \u001b[38;5;241m=\u001b[39m train_test_split_data(data_unified)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_new_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mever\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m data_unified\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/model.py:41\u001b[0m, in \u001b[0;36mcreate_new_model\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mCreates a new model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m     32\u001b[0m     TfidfVectorizer(\n\u001b[1;32m     33\u001b[0m         ngram_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     40\u001b[0m     )\n\u001b[0;32m---> 41\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1314\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2090\u001b[0m )\n\u001b[0;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:108\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:66\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 66\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "unified_data\n",
    "\n",
    "unified_data = unified_data.sample(frac=0.01, random_state=42)\n",
    "\n",
    "print(\"wait\")\n",
    "X_train, X_test, y_train, y_test  = train_test_split_data(unified_data)\n",
    "print(\"for\")\n",
    "model = create_new_model(X_train, y_train)\n",
    "print(\"ever\")\n",
    "unified_data\n",
    "#model = load_model('model.pkl', MODEL_PATH)\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_pred, y_test)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ddd024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>awm.com</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>http://awm.com/church-congregation-brings-gift...</td>\n",
       "      <td>Sometimes the power of Christmas will make you...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Church Congregation Brings Gift to Waitresses ...</td>\n",
       "      <td>Ruth Harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/awakening-start-here/...</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>AWAKENING OF 12 STRANDS of DNA – “Reconnecting...</td>\n",
       "      <td>Zurich Times</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>cnnnext.com</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>http://www.cnnnext.com/video/18526/never-hike-...</td>\n",
       "      <td>Never Hike Alone: A Friday the 13th Fan Film U...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Never Hike Alone - A Friday the 13th Fan Film ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>Never Hike Alone: A Friday the 13th Fan Film  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>768</td>\n",
       "      <td>awm.com</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>http://awm.com/elusive-alien-of-the-sea-caught...</td>\n",
       "      <td>When a rare shark was caught, scientists were ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Elusive ‘Alien Of The Sea ‘ Caught By Scientis...</td>\n",
       "      <td>Alexander Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>791</td>\n",
       "      <td>bipartisanreport.com</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>http://bipartisanreport.com/2018/01/21/trumps-...</td>\n",
       "      <td>Donald Trump has the unnerving ability to abil...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Trump’s Genius Poll Is Complete &amp; The Results ...</td>\n",
       "      <td>Gloria Christie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id                domain        type  \\\n",
       "0           0  141               awm.com  unreliable   \n",
       "1           1  256     beforeitsnews.com        fake   \n",
       "2           2  700           cnnnext.com  unreliable   \n",
       "3           3  768               awm.com  unreliable   \n",
       "4           4  791  bipartisanreport.com   clickbait   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://awm.com/church-congregation-brings-gift...   \n",
       "1  http://beforeitsnews.com/awakening-start-here/...   \n",
       "2  http://www.cnnnext.com/video/18526/never-hike-...   \n",
       "3  http://awm.com/elusive-alien-of-the-sea-caught...   \n",
       "4  http://bipartisanreport.com/2018/01/21/trumps-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Sometimes the power of Christmas will make you...   \n",
       "1  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
       "2  Never Hike Alone: A Friday the 13th Fan Film U...   \n",
       "3  When a rare shark was caught, scientists were ...   \n",
       "4  Donald Trump has the unnerving ability to abil...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-02 01:19:41.756664   \n",
       "1  2018-02-02 01:19:41.756664   \n",
       "2  2018-02-02 01:19:41.756664   \n",
       "3  2018-02-02 01:19:41.756664   \n",
       "4  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                               title          authors  \\\n",
       "0  Church Congregation Brings Gift to Waitresses ...      Ruth Harris   \n",
       "1  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...     Zurich Times   \n",
       "2  Never Hike Alone - A Friday the 13th Fan Film ...              NaN   \n",
       "3  Elusive ‘Alien Of The Sea ‘ Caught By Scientis...  Alexander Smith   \n",
       "4  Trump’s Genius Poll Is Complete & The Results ...  Gloria Christie   \n",
       "\n",
       "   keywords meta_keywords                                   meta_description  \\\n",
       "0       NaN          ['']                                                NaN   \n",
       "1       NaN          ['']                                                NaN   \n",
       "2       NaN          ['']  Never Hike Alone: A Friday the 13th Fan Film  ...   \n",
       "3       NaN          ['']                                                NaN   \n",
       "4       NaN          ['']                                                NaN   \n",
       "\n",
       "  tags  summary  \n",
       "0  NaN      NaN  \n",
       "1  NaN      NaN  \n",
       "2  NaN      NaN  \n",
       "3  NaN      NaN  \n",
       "4  NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_fnc_unprocessed = pd.read_csv('/Users/ssadegh/code/FakeNewsNet/cyb-news/data/corpus_news_sample.csv')\n",
    "# data_fnc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594822c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fnc_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_fnc \u001b[38;5;241m=\u001b[39m \u001b[43mfnc_preprocessing\u001b[49m(data_fnc)\n\u001b[1;32m      2\u001b[0m data_fnc\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fnc_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "data_fnc = fnc_preprocessing(data_fnc)\n",
    "data_fnc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49b2727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc = pd.read_csv('/Users/ssadegh/Downloads/FakeNewsNet/cyb-news/data/CrediCoal_Fake.csv')\n",
    "data_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037b9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssadegh/.pyenv/versions/3.10.6/envs/cybnews/lib/python3.10/site-packages/cybnews/data.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"label\"] = data.label.replace(to_replace=['REAL', 'FAKE'], value=[0, 1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smell hillary fear daniel greenfield shillman ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch exact moment paul ryan commit political ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerry go paris gesture sympathy u secretary st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernie supporter twitter erupt anger against d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battle new york primary matter primary day new...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    all_text_cleaned  label\n",
       "0  smell hillary fear daniel greenfield shillman ...      1\n",
       "1  watch exact moment paul ryan commit political ...      1\n",
       "2  kerry go paris gesture sympathy u secretary st...      0\n",
       "3  bernie supporter twitter erupt anger against d...      1\n",
       "4  battle new york primary matter primary day new...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc = get_data('/Users/ssadegh/code/FakeNewsNet/dataset/CrediCoal_Fake.csv')\n",
    "\n",
    "data_cc = join_text(data_cc)\n",
    "data_cc = cc_preprocessing(data_cc)\n",
    "\n",
    "data_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3fac2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/ssadegh/Downloads/FakeNewsNet/cyb-news/data/WELFake_Dataset.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd667a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f995b400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72134, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53900985",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23be1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "...          ...                                                ...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ddd9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        Unnamed: 0                                              title  \\\n",
       "0               0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1               1                                                NaN   \n",
       "2               2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3               3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4               4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "...           ...                                                ...   \n",
       "72129       72129  Russians steal research on Trump in hack of U....   \n",
       "72130       72130   WATCH: Giuliani Demands That Democrats Apolog...   \n",
       "72131       72131  Migrants Refuse To Leave Train At Refugee Camp...   \n",
       "72132       72132  Trump tussle gives unpopular Mexican leader mu...   \n",
       "72133       72133  Goldman Sachs Endorses Hillary Clinton For Pre...   \n",
       "\n",
       "                                                    text  label  \n",
       "0      No comment is expected from Barack Obama Membe...      1  \n",
       "1         Did they post their votes for Hillary already?      1  \n",
       "2       Now, most of the demonstrators gathered last ...      1  \n",
       "3      A dozen politically active pastors came here f...      0  \n",
       "4      The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "...                                                  ...    ...  \n",
       "72129  WASHINGTON (Reuters) - Hackers believed to be ...      0  \n",
       "72130  You know, because in fantasyland Republicans n...      1  \n",
       "72131  Migrants Refuse To Leave Train At Refugee Camp...      0  \n",
       "72132  MEXICO CITY (Reuters) - Donald Trump’s combati...      0  \n",
       "72133  Goldman Sachs Endorses Hillary Clinton For Pre...      1  \n",
       "\n",
       "[72134 rows x 4 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a736cef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72134.000000</td>\n",
       "      <td>72134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36066.500000</td>\n",
       "      <td>0.514404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20823.436496</td>\n",
       "      <td>0.499796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18033.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36066.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54099.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72133.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         label\n",
       "count  72134.000000  72134.000000\n",
       "mean   36066.500000      0.514404\n",
       "std    20823.436496      0.499796\n",
       "min        0.000000      0.000000\n",
       "25%    18033.250000      0.000000\n",
       "50%    36066.500000      1.000000\n",
       "75%    54099.750000      1.000000\n",
       "max    72133.000000      1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8df98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "REAL    0.500552\n",
       "FAKE    0.499448\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e5f66cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.514404\n",
       "0    0.485596\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e259d158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "title         False\n",
       "text          False\n",
       "label         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb4fc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "title         0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e4979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRows_cc = data_cc[data_cc.duplicated()]\n",
    "duplicateRows_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3360f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRows = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ec92dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a472be7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "title          True\n",
       "text           True\n",
       "label         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "78ee9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "title         558\n",
       "text           39\n",
       "label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c663a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cybnews.data import get_data\n",
    "df = get_data(\"/Users/ssadegh/Downloads/FakeNewsNet/cyb-news/data/WELFake_Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ae99bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "da792fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"all_text\"] = data[\"title\"] + \" \" +  data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "60db3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>all_text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                      \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  No comment is expected from Barack Obama Membe...      1   \n",
       "1     Did they post their votes for Hillary already?      1   \n",
       "2   Now, most of the demonstrators gathered last ...      1   \n",
       "3  A dozen politically active pastors came here f...      0   \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1   \n",
       "\n",
       "                                            all_text  text_length  \n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...         5180  \n",
       "1     Did they post their votes for Hillary already?           47  \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...          354  \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...         8116  \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...         2012  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_length'] = data['all_text'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "89670133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    3565.107286\n",
       "1    3139.031208\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label')['text_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b5daae2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([6.358e+03, 5.663e+03, 7.832e+03, 4.112e+03, 3.355e+03, 2.598e+03,\n",
       "        1.771e+03, 1.331e+03, 7.570e+02, 4.070e+02, 2.120e+02, 1.250e+02,\n",
       "        7.400e+01, 6.400e+01, 7.100e+01, 3.900e+01, 2.200e+01, 2.800e+01,\n",
       "        2.100e+01, 2.900e+01, 1.100e+01, 1.700e+01, 8.000e+00, 1.000e+01,\n",
       "        1.800e+01, 9.000e+00, 1.300e+01, 7.000e+00, 4.000e+00]),\n",
       " array([    0.        ,  1034.48275862,  2068.96551724,  3103.44827586,\n",
       "         4137.93103448,  5172.4137931 ,  6206.89655172,  7241.37931034,\n",
       "         8275.86206897,  9310.34482759, 10344.82758621, 11379.31034483,\n",
       "        12413.79310345, 13448.27586207, 14482.75862069, 15517.24137931,\n",
       "        16551.72413793, 17586.20689655, 18620.68965517, 19655.17241379,\n",
       "        20689.65517241, 21724.13793103, 22758.62068966, 23793.10344828,\n",
       "        24827.5862069 , 25862.06896552, 26896.55172414, 27931.03448276,\n",
       "        28965.51724138, 30000.        ]),\n",
       " <BarContainer object of 29 artists>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import plt\n",
    "import numpy as np\n",
    "\n",
    "bin = np.linspace(0, 1000, 30)\n",
    "plt.hist(data[data[\"label\"]== 1][\"text_length\"], bins=bin)\n",
    "plt.hist(data[data[\"label\"]== 0][\"text_length\"], bins=bin, alpha= 0.5)\n",
    "plt.show();\n",
    "bin = np.linspace(0, 30000, 30)\n",
    "plt.hist(data[data[\"label\"]== 1][\"text_length\"], bins=bin)\n",
    "plt.hist(data[data[\"label\"]== 0][\"text_length\"], bins=bin, alpha= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd00063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "98666148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>all_text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                      \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  No comment is expected from Barack Obama Membe...      1   \n",
       "1     Did they post their votes for Hillary already?      1   \n",
       "2   Now, most of the demonstrators gathered last ...      1   \n",
       "3  A dozen politically active pastors came here f...      0   \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1   \n",
       "\n",
       "                                            all_text  text_length  \n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...         5180  \n",
       "1     Did they post their votes for Hillary already?           47  \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...          354  \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...         8116  \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...         2012  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One could argue to only use data[\"text\"] as X\n",
    "\n",
    "\n",
    "data[\"all_text\"]\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "02428edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_data(df: pd.DataFrame) -> pd.DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "21c049e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def preprocessing(sentence):\\n    sentence = sentence.strip()\\n    sentence = sentence.lower()\\n    sentence = \"\".join(char for char in sentence if not char.isdigit())\\n    for x in string.punctuation:\\n        sentence = sentence.replace(x, \"\")\\n\\n    for x in \"’\":\\n        sentence = sentence.replace(x, \"\")\\n    #for x in \\'\"\"\\':\\n        #sentence = sentence.replace(x, \"\")\\n\\n    tokens = word_tokenize(sentence)\\n    language = set(stopwords.words(\"english\"))\\n    sentence = [w for  w in tokens if not w in language]\\n    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\\n    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\\n    return \\' \\'.join(n_l)\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\"\"\"def preprocessing(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = \"\".join(char for char in sentence if not char.isdigit())\n",
    "    for x in string.punctuation:\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    for x in \"’\":\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "    #for x in '\"\"':\n",
    "        #sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    tokens = word_tokenize(sentence)\n",
    "    language = set(stopwords.words(\"english\"))\n",
    "    sentence = [w for  w in tokens if not w in language]\n",
    "    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\n",
    "    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\n",
    "    return ' '.join(n_l)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826a65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f7cc37e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import string\\nfrom nltk.corpus import stopwords\\nfrom nltk import word_tokenize\\nfrom nltk.stem import WordNetLemmatizer\\nfrom collections import Counter\\n\\n\\ndef preprocessing(sentence):\\n    sentence = sentence.strip()\\n    sentence = sentence.lower()\\n    sentence = \"\".join(char for char in sentence if not char.isdigit())\\n    for x in string.punctuation:\\n        sentence = sentence.replace(x, \"\")\\n\\n    for x in \"’\":\\n        sentence = sentence.replace(x, \"\")\\n    #for x in \\'\"\"\\':\\n        #sentence = sentence.replace(x, \"\")\\n\\n    tokens = word_tokenize(sentence)\\n\\n    language = set(stopwords.words(\"english\"))\\n    #language.update()\\n    language.difference_update([\"not\", \"no\",\"nor\", \"against\", \"however\", \"but\", \"never\", \"should\", \"would\" , \"could\", \"might\", \"must\", \"no\", \"yes\", \"always\", \"none\", \"only\", \"still\", \"yet\", \"despite\", \"unless\", \"until\", \"cannot\" ])\\n    sentence = [w for  w in tokens if not w in language]\\n    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\\n    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\\n    return \\' \\'.join(n_l)'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = \"\".join(char for char in sentence if not char.isdigit())\n",
    "    for x in string.punctuation:\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    for x in \"’\":\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "    #for x in '\"\"':\n",
    "        #sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    language = set(stopwords.words(\"english\"))\n",
    "    #language.update()\n",
    "    language.difference_update([\"not\", \"no\",\"nor\", \"against\", \"however\", \"but\", \"never\", \"should\", \"would\" , \"could\", \"might\", \"must\", \"no\", \"yes\", \"always\", \"none\", \"only\", \"still\", \"yet\", \"despite\", \"unless\", \"until\", \"cannot\" ])\n",
    "    sentence = [w for  w in tokens if not w in language]\n",
    "    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\n",
    "    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\n",
    "    return ' '.join(n_l)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382acc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89c211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "87721859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say: 3266\n",
      "“: 2915\n",
      "”: 2913\n",
      "trump: 2031\n",
      "not: 1894\n",
      "but: 1571\n",
      "state: 1264\n",
      "would: 1202\n",
      "u: 1106\n",
      "one: 944\n",
      "people: 889\n",
      "make: 853\n",
      "new: 839\n",
      "mr: 837\n",
      "clinton: 835\n",
      "president: 816\n",
      "time: 799\n",
      "year: 795\n",
      "go: 739\n",
      "no: 672\n",
      "also: 659\n",
      "get: 655\n",
      "take: 633\n",
      "like: 626\n",
      "republican: 603\n",
      "call: 564\n",
      "—: 558\n",
      "tell: 550\n",
      "obama: 533\n",
      "american: 513\n",
      "could: 510\n",
      "come: 498\n",
      "house: 496\n",
      "work: 492\n",
      "use: 491\n",
      "government: 491\n",
      "first: 475\n",
      "white: 475\n",
      "country: 475\n",
      "even: 473\n",
      "two: 472\n",
      "campaign: 472\n",
      "against: 456\n",
      "hillary: 451\n",
      "right: 449\n",
      "day: 445\n",
      "think: 445\n",
      "election: 442\n",
      "report: 434\n",
      "only: 431\n",
      "know: 428\n",
      "vote: 421\n",
      "see: 419\n",
      "donald: 417\n",
      "last: 417\n",
      "many: 409\n",
      "official: 409\n",
      "unite: 407\n",
      "give: 407\n",
      "news: 406\n",
      "group: 398\n",
      "plan: 386\n",
      "include: 381\n",
      "need: 379\n",
      "want: 368\n",
      "world: 366\n",
      "way: 363\n",
      "former: 359\n",
      "may: 357\n",
      "back: 353\n",
      "law: 350\n",
      "political: 345\n",
      "show: 343\n",
      "party: 339\n",
      "national: 336\n",
      "become: 335\n",
      "support: 335\n",
      "million: 333\n",
      "try: 328\n",
      "leave: 327\n",
      "medium: 324\n",
      "ask: 320\n",
      "should: 320\n",
      "court: 320\n",
      "week: 318\n",
      "case: 315\n",
      "find: 311\n",
      "email: 311\n",
      "attack: 310\n",
      "policy: 307\n",
      "city: 304\n",
      "video: 299\n",
      "york: 292\n",
      "america: 290\n",
      "live: 288\n",
      "since: 287\n",
      "reuters: 286\n",
      "well: 285\n",
      "help: 283\n",
      "accord: 283\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "def word_count(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = \"\".join(char for char in sentence if not char.isdigit())\n",
    "    for x in string.punctuation:\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "    for x in \"’\":\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "    tokens = word_tokenize(sentence)\n",
    "    language = set(stopwords.words(\"english\"))\n",
    "    sentence = [w for  w in tokens if not w in language]\n",
    "    language.difference_update([\"not\", \"no\",\"nor\", \"against\", \"however\", \"but\", \"never\", \"should\", \"would\" , \"could\", \"might\", \"must\", \"no\", \"yes\", \"always\", \"none\", \"only\", \"still\", \"yet\", \"despite\", \"unless\", \"until\", \"cannot\" ])\n",
    "\n",
    "    sentence = [w for  w in tokens if not w in language]\n",
    "    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\n",
    "    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\n",
    "    word_counts = Counter(n_l)\n",
    "\n",
    "    return word_counts\n",
    "\n",
    "total_word_counts = Counter()\n",
    "data[\"all_text_cleaned_test\"] = data[\"all_text\"].apply(word_count)\n",
    "for counts in data[\"all_text_cleaned_test\"]:\n",
    "    total_word_counts.update(counts)\n",
    "total = sum(total_word_counts.values())\n",
    "\n",
    "most_common_words = total_word_counts.most_common(100)\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b468ef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23652972"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ea4bdf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#len(stopwords.words(\"english\"))\n",
    "\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b51107fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = \"\".join(char for char in sentence if not char.isdigit())\n",
    "    for x in string.punctuation:\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    for x in \"’\":\n",
    "        sentence = sentence.replace(x, \"\")\n",
    "    #for x in '\"\"':\n",
    "        #sentence = sentence.replace(x, \"\")\n",
    "\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    language = set(stopwords.words(\"english\"))\n",
    "    language.update([\"trump\", \"clinton\", \"obama\"])\n",
    "    language.difference_update([\"not\", \"no\",\"nor\", \"against\", \"however\", \"but\", \"never\", \"should\", \"would\" , \"could\", \"might\", \"must\", \"no\", \"yes\", \"always\", \"none\", \"only\", \"still\", \"yet\", \"despite\", \"unless\", \"until\", \"cannot\" ])\n",
    "    sentence = [w for  w in tokens if not w in language]\n",
    "    v_l = [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in sentence]\n",
    "    n_l = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in v_l]\n",
    "    return ' '.join(n_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "20628ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "be836ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"all_text_cleaned\"] = data[\"all_text\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90398050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "75e80b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_ready = data[[\"all_text_cleaned\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5417b7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61370</th>\n",
       "      <td>arnold schwarzenegger send message liberal whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>wow “ mexican need kill donald become presiden...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60609</th>\n",
       "      <td>jimmy carter recover dehydration scare canada ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51565</th>\n",
       "      <td>friar mission revive brooklyn church religious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39431</th>\n",
       "      <td>boy autism make first friend ever mom cant sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46006</th>\n",
       "      <td>condemn trump…says u “ bless muslim community ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33197</th>\n",
       "      <td>czech foreign minister lightly injure car acci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61712</th>\n",
       "      <td>house intel slap subpoena mccain institute ass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17836</th>\n",
       "      <td>terror group plan violence against supporter s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47596</th>\n",
       "      <td>wheres medium blm block street storm football ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        all_text_cleaned  label\n",
       "61370  arnold schwarzenegger send message liberal whi...      1\n",
       "2189   wow “ mexican need kill donald become presiden...      1\n",
       "60609  jimmy carter recover dehydration scare canada ...      0\n",
       "51565  friar mission revive brooklyn church religious...      0\n",
       "39431  boy autism make first friend ever mom cant sto...      1\n",
       "...                                                  ...    ...\n",
       "46006  condemn trump…says u “ bless muslim community ...      1\n",
       "33197  czech foreign minister lightly injure car acci...      0\n",
       "61712  house intel slap subpoena mccain institute ass...      1\n",
       "17836  terror group plan violence against supporter s...      1\n",
       "47596  wheres medium blm block street storm football ...      1\n",
       "\n",
       "[7213 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9e4f1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_ready[\"label\"]\n",
    "X = data_ready[\"all_text_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ad7ba315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61370    arnold schwarzenegger send message liberal whi...\n",
       "2189     wow “ mexican need kill donald become presiden...\n",
       "60609    jimmy carter recover dehydration scare canada ...\n",
       "51565    friar mission revive brooklyn church religious...\n",
       "39431    boy autism make first friend ever mom cant sto...\n",
       "Name: all_text_cleaned, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8382f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "81c407be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16886    microsoft find cancer clue search query new yo...\n",
       "63308    kamala harrisleftist senator california next d...\n",
       "64617    indonesian parliament speaker name suspect mas...\n",
       "61031    turkey say recognize jerusalem capital would c...\n",
       "36853    obamas dream america nightmare illegal alien c...\n",
       "                               ...                        \n",
       "52834    candidate run president only one pay intern ni...\n",
       "68373    virginia judge issue new injunction against tr...\n",
       "10527    right group urge eu japan consider halt fund c...\n",
       "27342    choose best battery prepper solar system carme...\n",
       "34276    spacex rocket explode launchpad cape canaveral...\n",
       "Name: all_text_cleaned, Length: 5049, dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1c4ec508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe = make_pipeline(CountVectorizer(),MultinomialNB())\n",
    "\n",
    "####\n",
    "#grid_search\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5a57df58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('countvectorizer', CountVectorizer()),\n",
       "  ('multinomialnb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'countvectorizer': CountVectorizer(),\n",
       " 'multinomialnb': MultinomialNB(),\n",
       " 'countvectorizer__analyzer': 'word',\n",
       " 'countvectorizer__binary': False,\n",
       " 'countvectorizer__decode_error': 'strict',\n",
       " 'countvectorizer__dtype': numpy.int64,\n",
       " 'countvectorizer__encoding': 'utf-8',\n",
       " 'countvectorizer__input': 'content',\n",
       " 'countvectorizer__lowercase': True,\n",
       " 'countvectorizer__max_df': 1.0,\n",
       " 'countvectorizer__max_features': None,\n",
       " 'countvectorizer__min_df': 1,\n",
       " 'countvectorizer__ngram_range': (1, 1),\n",
       " 'countvectorizer__preprocessor': None,\n",
       " 'countvectorizer__stop_words': None,\n",
       " 'countvectorizer__strip_accents': None,\n",
       " 'countvectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'countvectorizer__tokenizer': None,\n",
       " 'countvectorizer__vocabulary': None,\n",
       " 'multinomialnb__alpha': 1.0,\n",
       " 'multinomialnb__class_prior': None,\n",
       " 'multinomialnb__fit_prior': True,\n",
       " 'multinomialnb__force_alpha': True}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4b79841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/pipeline.py\", line 472, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/pipeline.py\", line 409, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1329, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\", line 1356, in fit_transform\n",
      "    self._validate_ngram_range()\n",
      "  File \"/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\", line 516, in _validate_ngram_range\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for ngram_range=(2, 1) lower boundary larger than the upper boundary.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/admin/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.87700556 0.8776006  0.8673024         nan        nan        nan\n",
      " 0.88413585 0.88948454 0.86591704 0.86551983 0.87621525 0.87423564]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8894845401289386"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid = {\"countvectorizer__ngram_range\": ((1,1), (2,1), (1,2), (2,2)),\n",
    "        \"multinomialnb__alpha\": (0.01, 0.1, 1)}\n",
    "\n",
    "\n",
    "search_g = GridSearchCV(pipe,grid, scoring = \"accuracy\", cv =5, n_jobs=-1)\n",
    "\n",
    "search_g.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "search_g.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "38432fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__ngram_range': (1, 2), 'multinomialnb__alpha': 0.1}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_g.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b5728201",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = search_g.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "198cfca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932532347504621"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f6f9426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible Tokenizer -> Bag of Words, Tf-Idf Embedding, BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f6fa905c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nM\\n1.Bag of Words (BoW):\\nNaive Bayes\\nSVM\\nLogistic Regression\\nRandom Forest\\n\\n2.TF-IDF:\\nNaive Bayes\\nSVM\\nLogistic Regression\\nRandom Forest\\n\\n\\nDeep\\n3.Word Embeddings:\\nSVM\\nLogistic Regression\\nDeep Learning (LSTM, CNN)\\nTransformers (prepare=)\\n\\n4.Transformers:\\nDeep Learning (LSTM, CNN)\\nTransformers models'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "M\n",
    "1.Bag of Words (BoW):\n",
    "Naive Bayes\n",
    "SVM\n",
    "Logistic Regression\n",
    "Random Forest\n",
    "\n",
    "2.TF-IDF:\n",
    "Naive Bayes\n",
    "SVM\n",
    "Logistic Regression\n",
    "Random Forest\n",
    "\n",
    "\n",
    "Deep\n",
    "3.Word Embeddings:\n",
    "SVM\n",
    "Logistic Regression\n",
    "Deep Learning (LSTM, CNN)\n",
    "Transformers (prepare=)\n",
    "\n",
    "4.Transformers:\n",
    "Deep Learning (LSTM, CNN)\n",
    "Transformers models\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "14a461f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights:\n",
    "# Model without Obama, Trump and Clinton drops the score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
